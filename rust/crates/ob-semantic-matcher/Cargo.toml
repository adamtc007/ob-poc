[package]
name = "ob-semantic-matcher"
version = "0.1.0"
edition = "2021"
description = "Semantic voice command matching using Candle ML and pgvector"

[features]
default = []
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]

[dependencies]
# Candle - Pure Rust ML framework from HuggingFace
# Enable metal feature for Mac GPU acceleration
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"

# HuggingFace Hub for model download
hf-hub = "0.4"

# Fast tokenizer (same as Python transformers)
tokenizers = "0.20"

# Double Metaphone for phonetic matching
rphonetic = "2.0"

# Database
sqlx = { version = "0.8", features = ["runtime-tokio-rustls", "postgres", "uuid", "chrono"] }
pgvector = { version = "0.4", features = ["sqlx"] }

# Async runtime
tokio = { version = "1", features = ["sync", "rt-multi-thread", "macros"] }

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# UUID for database IDs
uuid = { version = "1.20", features = ["v4", "serde", "v7"] }

# Async trait for trait async methods
async-trait = "0.1"

# Regex for input sanitization
regex = "1.10"
once_cell = "1.19"

# Parallel processing
rayon = "1.10"

# Hashing for input deduplication
sha2 = "0.10"
hex = "0.4"

# DateTime for analysis
chrono = { version = "0.4", features = ["serde"] }

# CLI argument parsing
clap = { version = "4.4", features = ["derive"] }

[[bin]]
name = "populate_embeddings"
path = "src/bin/populate_embeddings.rs"

[dev-dependencies]
tokio = { version = "1", features = ["full", "test-util"] }
