diff --git a/rust/src/api/agent_service.rs b/rust/src/api/agent_service.rs
index 848bbd3..60c2fa4 100644
--- a/rust/src/api/agent_service.rs
+++ b/rust/src/api/agent_service.rs
@@ -1742,6 +1742,7 @@ impl AgentService {
         program: crate::dsl_v2::ast::Program,
     ) -> Result<AgentChatResponse, String> {
         use crate::repl::executor_bridge::RealDslExecutor;
+        use crate::runbook::executor::RunbookStoreBackend;
         use crate::runbook::step_executor_bridge::DslStepExecutor;
         use crate::runbook::{
             envelope::ReplayEnvelope,
@@ -1751,7 +1752,16 @@ impl AgentService {
             CompiledRunbook, RunbookStore,
         };
 
-        let store = RunbookStore::new();
+        // Phase D: use Postgres store when pool available for event emission.
+        #[cfg(feature = "database")]
+        let pg_store = crate::runbook::executor::PostgresRunbookStore::new(self.pool.clone());
+        #[cfg(feature = "database")]
+        let store: &dyn RunbookStoreBackend = &pg_store;
+
+        #[cfg(not(feature = "database"))]
+        let mem_store = RunbookStore::new();
+        #[cfg(not(feature = "database"))]
+        let store: &dyn RunbookStoreBackend = &mem_store;
         let session_id = session.id;
         let mut executed_count = 0usize;
 
@@ -1766,11 +1776,8 @@ impl AgentService {
                 let dsl_source = vc.to_dsl_string();
 
                 // Derive write_set from args (heuristic UUID extraction)
-                let args_hashmap: std::collections::HashMap<String, String> =
-                    args.iter().map(|(k, v)| (k.clone(), v.clone())).collect();
-                let write_set: Vec<uuid::Uuid> = derive_write_set_heuristic(&args_hashmap)
-                    .into_iter()
-                    .collect();
+                let write_set: Vec<uuid::Uuid> =
+                    derive_write_set_heuristic(&args).into_iter().collect();
 
                 let step = CompiledStep {
                     step_id: uuid::Uuid::new_v4(),
@@ -1784,8 +1791,12 @@ impl AgentService {
                 };
 
                 let envelope = ReplayEnvelope {
-                    session_cursor: 0,
-                    entity_bindings: std::collections::BTreeMap::new(),
+                    core: crate::runbook::envelope::EnvelopeCore {
+                        session_cursor: 0,
+                        entity_bindings: std::collections::BTreeMap::new(),
+                        external_lookup_digests: vec![],
+                        macro_audit_digests: vec![],
+                    },
                     external_lookups: vec![],
                     macro_audits: vec![],
                     sealed_at: chrono::Utc::now(),
@@ -1798,12 +1809,15 @@ impl AgentService {
                     envelope,
                 );
                 let runbook_id = runbook.id;
-                store.insert(runbook);
+                if let Err(e) = store.insert(&runbook).await {
+                    let msg = format!("Failed to store compiled runbook: {}", e);
+                    return Ok(self.fail(&msg, session));
+                }
 
                 // Execute through the gate (INV-1)
                 let real_executor = RealDslExecutor::new(self.pool.clone());
                 let step_executor = DslStepExecutor::new(std::sync::Arc::new(real_executor));
-                match execute_runbook(&store, runbook_id, None, &step_executor).await {
+                match execute_runbook(store, runbook_id, None, &step_executor).await {
                     Ok(_result) => {
                         executed_count += 1;
                     }
diff --git a/rust/src/database/locks.rs b/rust/src/database/locks.rs
index c2a398f..6ae7964 100644
--- a/rust/src/database/locks.rs
+++ b/rust/src/database/locks.rs
@@ -147,6 +147,11 @@ pub enum LockError {
         entity_id: String,
         /// Locks that were acquired before contention occurred
         acquired_so_far: Vec<LockKey>,
+        /// Best-effort: the compiled runbook ID currently holding the lock (INV-10).
+        /// Populated by querying `compiled_runbook_events` for the most recent
+        /// `lock_acquired` event on the contested entity. `None` if lookup fails
+        /// or no holder is found (advisory locks are anonymous in PostgreSQL).
+        holder_runbook_id: Option<uuid::Uuid>,
     },
 
     /// Database error
@@ -248,6 +253,7 @@ pub async fn acquire_locks(
                         entity_type: lock.entity_type.clone(),
                         entity_id: lock.entity_id.clone(),
                         acquired_so_far: acquired,
+                        holder_runbook_id: None, // Populated by caller via event store lookup
                     });
                 }
                 return Err(LockError::Database(e));
@@ -273,6 +279,7 @@ pub async fn acquire_locks(
                 entity_type: lock.entity_type.clone(),
                 entity_id: lock.entity_id.clone(),
                 acquired_so_far: acquired,
+                holder_runbook_id: None, // Populated by caller via event store lookup
             });
         }
     }
diff --git a/rust/src/dsl_v2/executor.rs b/rust/src/dsl_v2/executor.rs
index f979b62..68782ec 100644
--- a/rust/src/dsl_v2/executor.rs
+++ b/rust/src/dsl_v2/executor.rs
@@ -1871,6 +1871,7 @@ impl DslExecutor {
                         entity_type,
                         entity_id,
                         acquired_so_far,
+                        ..
                     }) => {
                         // Rollback and return contention error
                         tx.rollback().await?;
diff --git a/rust/src/dsl_v2/macros/expander.rs b/rust/src/dsl_v2/macros/expander.rs
index dc30dde..212dc18 100644
--- a/rust/src/dsl_v2/macros/expander.rs
+++ b/rust/src/dsl_v2/macros/expander.rs
@@ -16,7 +16,7 @@
 //! Expanded: (cbu.create :kind private-equity :name "Acme Fund" :client_id uuid-123)
 //! ```
 
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 
 use chrono::Utc;
 use serde::{Deserialize, Serialize};
@@ -157,7 +157,7 @@ pub struct MacroExpansionAudit {
 /// Expanded DSL statements ready for the normal pipeline
 pub fn expand_macro(
     macro_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
     registry: &MacroRegistry,
 ) -> Result<MacroExpansionOutput, MacroExpansionError> {
@@ -251,7 +251,7 @@ pub fn expand_macro(
 /// 6. Repeat until no directives remain (fixpoint)
 pub fn expand_macro_fixpoint(
     macro_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
     registry: &MacroRegistry,
     limits: ExpansionLimits,
@@ -303,7 +303,7 @@ pub struct FixpointExpansionOutput {
 #[allow(clippy::too_many_arguments)]
 fn expand_macro_recursive(
     macro_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
     registry: &MacroRegistry,
     limits: ExpansionLimits,
@@ -344,9 +344,15 @@ fn expand_macro_recursive(
     for stmt in &output.statements {
         if let Some(invoke) = parse_invoke_macro_directive(stmt) {
             // Recursively expand the nested macro
+            // Convert HashMap → BTreeMap at internal/API boundary (INV-2)
+            let invoke_args_btree: BTreeMap<String, String> = invoke
+                .args
+                .iter()
+                .map(|(k, v)| (k.clone(), v.clone()))
+                .collect();
             let nested_statements = expand_macro_recursive(
                 &invoke.macro_id,
-                &invoke.args,
+                &invoke_args_btree,
                 session,
                 registry,
                 limits,
@@ -417,7 +423,7 @@ fn parse_invoke_macro_directive(line: &str) -> Option<InvokeMacroDirective> {
 /// Validate provided arguments against schema
 fn validate_args(
     schema: &MacroSchema,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
 ) -> Result<(), MacroExpansionError> {
     // Check all required args are present
     for (name, _spec) in schema.required_args() {
@@ -471,7 +477,7 @@ fn validate_args(
 /// Check if a required-if condition is satisfied
 fn is_required_if_satisfied(
     expr: &super::schema::RequiredIfExpr,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
 ) -> bool {
     use super::schema::RequiredIfExpr;
 
@@ -503,7 +509,7 @@ fn is_required_if_satisfied(
 }
 
 /// Evaluate a simple condition like "structure-type = ucits"
-fn evaluate_simple_required_if(condition: &str, args: &HashMap<String, String>) -> bool {
+fn evaluate_simple_required_if(condition: &str, args: &BTreeMap<String, String>) -> bool {
     let condition = condition.trim();
 
     // Handle equality: "var = value"
@@ -615,7 +621,7 @@ fn check_prereqs(
 /// Check structure type constraints for role assignments
 fn check_structure_type_constraints(
     schema: &MacroSchema,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
 ) -> Result<(), MacroExpansionError> {
     // Check target.allowed_structure_types
@@ -658,7 +664,7 @@ fn check_structure_type_constraints(
 /// Build variable context from args, scope, and session
 fn build_variable_context(
     schema: &MacroSchema,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
 ) -> Result<VariableContext, MacroExpansionError> {
     // Merge required and optional arg specs
@@ -1024,7 +1030,7 @@ structure.setup:
         let registry = mock_registry();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("structure-type".to_string(), "pe".to_string());
         args.insert("name".to_string(), "Acme Fund".to_string());
 
@@ -1053,7 +1059,7 @@ structure.setup:
         let registry = mock_registry();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         // Missing required "name" argument
         args.insert("structure-type".to_string(), "pe".to_string());
 
@@ -1069,7 +1075,7 @@ structure.setup:
         let registry = mock_registry();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("structure-type".to_string(), "invalid".to_string());
         args.insert("name".to_string(), "Acme".to_string());
 
@@ -1085,7 +1091,7 @@ structure.setup:
         let registry = mock_registry();
         let session = mock_session();
 
-        let result = expand_macro("unknown.macro", &HashMap::new(), &session, &registry);
+        let result = expand_macro("unknown.macro", &BTreeMap::new(), &session, &registry);
         assert!(matches!(result, Err(MacroExpansionError::UnknownMacro(_))));
     }
 
@@ -1182,7 +1188,7 @@ structure.assign-role:
         let registry = mock_registry_with_assign_role();
         let session = mock_session_pe();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert(
             "structure".to_string(),
             "22222222-2222-2222-2222-222222222222".to_string(),
@@ -1209,7 +1215,7 @@ structure.assign-role:
         let registry = mock_registry_with_assign_role();
         let session = mock_session_sicav();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert(
             "structure".to_string(),
             "22222222-2222-2222-2222-222222222222".to_string(),
@@ -1242,7 +1248,7 @@ structure.assign-role:
         let registry = mock_registry_with_assign_role();
         let session = mock_session_sicav();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert(
             "structure".to_string(),
             "22222222-2222-2222-2222-222222222222".to_string(),
@@ -1269,7 +1275,7 @@ structure.assign-role:
         let registry = mock_registry_with_assign_role();
         let session = mock_session_pe();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert(
             "structure".to_string(),
             "22222222-2222-2222-2222-222222222222".to_string(),
@@ -1308,7 +1314,7 @@ structure.assign-role:
         ] {
             let session = session_fn();
 
-            let mut args = HashMap::new();
+            let mut args = BTreeMap::new();
             args.insert(
                 "structure".to_string(),
                 "22222222-2222-2222-2222-222222222222".to_string(),
@@ -1475,7 +1481,7 @@ composite.deep:
         let registry = mock_registry_nested();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("x".to_string(), "hello".to_string());
         args.insert("y".to_string(), "world".to_string());
 
@@ -1539,7 +1545,7 @@ composite.deep:
         let registry = mock_registry_nested();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("x".to_string(), "deep-x".to_string());
         args.insert("y".to_string(), "deep-y".to_string());
 
@@ -1622,7 +1628,7 @@ cycle.b:
         let session = mock_session();
         let result = expand_macro_fixpoint(
             "cycle.a",
-            &HashMap::new(),
+            &BTreeMap::new(),
             &session,
             &registry,
             EXPANSION_LIMITS,
@@ -1687,7 +1693,7 @@ diamond.root:
         }
 
         let session = mock_session();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("x".to_string(), "unused".to_string());
 
         let result =
@@ -1789,7 +1795,8 @@ chain.{i}:
             max_steps: 500,
         };
 
-        let result = expand_macro_fixpoint("chain.0", &HashMap::new(), &session, &registry, limits);
+        let result =
+            expand_macro_fixpoint("chain.0", &BTreeMap::new(), &session, &registry, limits);
 
         assert!(
             matches!(&result, Err(MacroExpansionError::MaxDepthExceeded { depth, limit })
@@ -1873,7 +1880,8 @@ fan.out:
             max_steps: 2, // Only allow 2 steps — third should fail
         };
 
-        let result = expand_macro_fixpoint("fan.out", &HashMap::new(), &session, &registry, limits);
+        let result =
+            expand_macro_fixpoint("fan.out", &BTreeMap::new(), &session, &registry, limits);
 
         assert!(
             matches!(&result, Err(MacroExpansionError::MaxStepsExceeded { steps, limit })
@@ -1890,7 +1898,7 @@ fan.out:
         let session = mock_session();
 
         // Test leaf (only needs x)
-        let mut leaf_args = HashMap::new();
+        let mut leaf_args = BTreeMap::new();
         leaf_args.insert("x".to_string(), "val".to_string());
         let result = expand_macro_fixpoint(
             "leaf.alpha",
@@ -1910,7 +1918,7 @@ fan.out:
         }
 
         // Test composite and deep (need both x and y)
-        let mut composite_args = HashMap::new();
+        let mut composite_args = BTreeMap::new();
         composite_args.insert("x".to_string(), "val".to_string());
         composite_args.insert("y".to_string(), "val".to_string());
 
@@ -1944,7 +1952,7 @@ fan.out:
         let registry = mock_registry_nested();
         let session = mock_session();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("x".to_string(), "v".to_string());
         args.insert("y".to_string(), "v".to_string());
 
diff --git a/rust/src/dsl_v2/macros/variable.rs b/rust/src/dsl_v2/macros/variable.rs
index cc1d3f4..cb9644c 100644
--- a/rust/src/dsl_v2/macros/variable.rs
+++ b/rust/src/dsl_v2/macros/variable.rs
@@ -11,7 +11,7 @@
 
 use regex::Regex;
 use serde_json::Value;
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 use thiserror::Error;
 
 use super::schema::MacroArg;
@@ -119,7 +119,7 @@ impl VariableContext {
     /// Build context from macro args and provided values
     pub fn from_macro_args(
         args_spec: &HashMap<String, MacroArg>,
-        provided_args: &HashMap<String, String>,
+        provided_args: &BTreeMap<String, String>,
     ) -> Result<Self, VariableError> {
         let mut ctx = Self::new();
 
diff --git a/rust/src/mcp/macro_integration.rs b/rust/src/mcp/macro_integration.rs
index 0525bea..09f71e0 100644
--- a/rust/src/mcp/macro_integration.rs
+++ b/rust/src/mcp/macro_integration.rs
@@ -13,7 +13,7 @@
 //! }
 //! ```
 
-use std::collections::HashMap;
+use std::collections::BTreeMap;
 use std::sync::OnceLock;
 
 use anyhow::Result;
@@ -76,7 +76,7 @@ pub enum MacroAttemptResult {
 /// allowing normal processing to continue.
 pub fn try_expand_macro(
     verb_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
 ) -> MacroAttemptResult {
     let registry = macro_registry();
@@ -107,8 +107,8 @@ pub fn try_expand_macro(
 ///
 /// Extracts string values from IntentArguments for macro expansion.
 /// Enum values use the UI key (macro expansion handles internal mapping).
-pub fn intent_args_to_macro_args(intent: &StructuredIntent) -> HashMap<String, String> {
-    let mut args = HashMap::new();
+pub fn intent_args_to_macro_args(intent: &StructuredIntent) -> BTreeMap<String, String> {
+    let mut args = BTreeMap::new();
 
     for arg in &intent.arguments {
         if let Some(value) = extract_string_value(&arg.value) {
diff --git a/rust/src/plan_builder/errors.rs b/rust/src/plan_builder/errors.rs
index 88c9933..cf25b9a 100644
--- a/rust/src/plan_builder/errors.rs
+++ b/rust/src/plan_builder/errors.rs
@@ -52,7 +52,7 @@ impl ClassificationError {
             context: ClarificationContext {
                 verb: Some(self.verb_name),
                 is_macro: false,
-                extracted_args: std::collections::HashMap::new(),
+                extracted_args: std::collections::BTreeMap::new(),
             },
         })
     }
@@ -116,7 +116,7 @@ impl AssemblyError {
             context: ClarificationContext {
                 verb: None,
                 is_macro: false,
-                extracted_args: std::collections::HashMap::new(),
+                extracted_args: std::collections::BTreeMap::new(),
             },
         })
     }
diff --git a/rust/src/repl/orchestrator_v2.rs b/rust/src/repl/orchestrator_v2.rs
index d93c075..1e8a039 100644
--- a/rust/src/repl/orchestrator_v2.rs
+++ b/rust/src/repl/orchestrator_v2.rs
@@ -51,7 +51,9 @@ use crate::journey::template::instantiate_template;
 use crate::repl::intent_matcher::IntentMatcher;
 use crate::repl::types::{MatchContext, MatchOutcome};
 use crate::runbook::envelope::ReplayEnvelope;
-use crate::runbook::executor::{execute_runbook_with_pool, StepOutcome};
+#[cfg(feature = "database")]
+use crate::runbook::executor::PostgresRunbookStore;
+use crate::runbook::executor::{execute_runbook_with_pool, RunbookStoreBackend, StepOutcome};
 use crate::runbook::step_executor_bridge::{DslExecutorV2StepExecutor, DslStepExecutor};
 use crate::runbook::types::{
     CompiledRunbook, CompiledStep, ExecutionMode as CompiledExecutionMode,
@@ -3562,9 +3564,17 @@ impl ReplOrchestratorV2 {
                 .collect(),
             depends_on: vec![],
             execution_mode: compiled_mode,
-            write_set: derive_write_set(&entry.verb, &entry.args, None)
-                .into_iter()
-                .collect(),
+            write_set: derive_write_set(
+                &entry.verb,
+                &entry
+                    .args
+                    .iter()
+                    .map(|(k, v)| (k.clone(), v.clone()))
+                    .collect(),
+                None,
+            )
+            .into_iter()
+            .collect(),
         };
         CompiledRunbook::new(session_id, version, vec![step], ReplayEnvelope::empty())
     }
@@ -3588,18 +3598,31 @@ impl ReplOrchestratorV2 {
         runbook_id: Uuid,
         fallback_version: u64,
     ) -> StepOutcome {
-        let store = match self.runbook_store.as_ref() {
-            Some(s) => s,
-            None => {
-                // No store available — cannot enforce gate. This should not happen
-                // in production (store is always wired in main.rs).
-                tracing::error!(
-                    "RunbookStore not available — cannot enforce execution gate (INV-3)"
-                );
-                return StepOutcome::Failed {
-                    error: "Internal error: RunbookStore not configured".into(),
-                };
-            }
+        // Construct the store backend: Postgres when pool available, in-memory fallback.
+        // This ensures lock events, status events, and holder lookups fire in production
+        // (Phase D: RunbookStoreBackend trait wiring).
+        #[cfg(feature = "database")]
+        let pg_store: Option<PostgresRunbookStore> = self
+            .pool
+            .as_ref()
+            .map(|p| PostgresRunbookStore::new(p.clone()));
+
+        // Fallback in-memory store for when no pool (tests, non-database config).
+        let fallback_store: RunbookStore = RunbookStore::new();
+
+        #[cfg(feature = "database")]
+        let store: &dyn RunbookStoreBackend = if let Some(ref pg) = pg_store {
+            pg
+        } else if let Some(ref s) = self.runbook_store {
+            s.as_ref()
+        } else {
+            &fallback_store
+        };
+        #[cfg(not(feature = "database"))]
+        let store: &dyn RunbookStoreBackend = if let Some(ref s) = self.runbook_store {
+            s.as_ref()
+        } else {
+            &fallback_store
         };
 
         // Resolve or create the CompiledRunbookId.
@@ -3614,7 +3637,12 @@ impl ReplOrchestratorV2 {
             );
             let compiled = self.compile_entry_on_the_fly(entry, session_id, fallback_version);
             let id = compiled.id;
-            store.insert(compiled);
+            if let Err(e) = store.insert(&compiled).await {
+                tracing::error!(error = %e, "Failed to insert compiled runbook into store");
+                return StepOutcome::Failed {
+                    error: format!("Failed to store compiled runbook: {}", e),
+                };
+            }
             id
         };
 
@@ -3639,7 +3667,6 @@ impl ReplOrchestratorV2 {
                     None,
                     &bridge,
                     self.pool.as_ref(),
-                    None,
                 )
                 .await
                 {
@@ -3657,7 +3684,6 @@ impl ReplOrchestratorV2 {
                     None,
                     &bridge,
                     self.pool.as_ref(),
-                    None,
                 )
                 .await
                 {
@@ -3669,15 +3695,8 @@ impl ReplOrchestratorV2 {
             }
         } else {
             let bridge = DslStepExecutor::new(Arc::clone(&self.executor));
-            match execute_runbook_with_pool(
-                store,
-                compiled_id,
-                None,
-                &bridge,
-                self.pool.as_ref(),
-                None,
-            )
-            .await
+            match execute_runbook_with_pool(store, compiled_id, None, &bridge, self.pool.as_ref())
+                .await
             {
                 Ok(result) => extract_first_outcome(result),
                 Err(e) => StepOutcome::Failed {
@@ -3956,10 +3975,16 @@ impl ReplOrchestratorV2 {
 
         let classification = classify_verb(&entry.verb, &self.verb_config_index, macro_registry);
         let version = session.allocate_runbook_version();
+        // Convert HashMap → BTreeMap for deterministic iteration (INV-2, Phase C)
+        let args_btree: std::collections::BTreeMap<String, String> = entry
+            .args
+            .iter()
+            .map(|(k, v)| (k.clone(), v.clone()))
+            .collect();
         let response = compile_verb(
             session.id,
             &classification,
-            &entry.args,
+            &args_btree,
             &unified,
             macro_registry,
             version,
diff --git a/rust/src/runbook/canonical.rs b/rust/src/runbook/canonical.rs
index 2e4611b..5b62829 100644
--- a/rust/src/runbook/canonical.rs
+++ b/rust/src/runbook/canonical.rs
@@ -28,7 +28,7 @@
 use sha2::{Digest, Sha256};
 use uuid::Uuid;
 
-use super::envelope::{MacroExpansionAudit, ReplayEnvelope};
+use super::envelope::{EnvelopeCore, MacroExpansionAudit, ReplayEnvelope};
 use super::types::{CompiledRunbookId, CompiledStep};
 
 // ---------------------------------------------------------------------------
@@ -37,16 +37,32 @@ use super::types::{CompiledRunbookId, CompiledStep};
 
 /// Serialize a slice of compiled steps to deterministic bincode bytes.
 pub fn canonical_bytes_for_steps(steps: &[CompiledStep]) -> Vec<u8> {
+    // SAFETY: all fields are primitives, BTreeMaps, Vecs, and Strings —
+    // bincode serialization cannot fail for these types.
     bincode::serialize(steps).expect("bincode serialization of CompiledStep slice is infallible")
 }
 
-/// Serialize a replay envelope to deterministic bincode bytes.
+/// Serialize an envelope core to deterministic bincode bytes.
+///
+/// Only the `EnvelopeCore` (no timestamps) feeds into the content-addressed
+/// hash. The full `ReplayEnvelope` is stored for audit but not hashed.
+pub fn canonical_bytes_for_envelope_core(core: &EnvelopeCore) -> Vec<u8> {
+    // SAFETY: all fields are primitives, BTreeMaps, Vecs, and Strings —
+    // bincode serialization cannot fail for these types.
+    bincode::serialize(core).expect("bincode serialization of EnvelopeCore is infallible")
+}
+
+/// Serialize a full replay envelope to deterministic bincode bytes.
+///
+/// Used for storage/integrity checks, NOT for content-addressed ID hashing.
+/// For ID hashing, use `canonical_bytes_for_envelope_core()`.
 pub fn canonical_bytes_for_envelope(envelope: &ReplayEnvelope) -> Vec<u8> {
     bincode::serialize(envelope).expect("bincode serialization of ReplayEnvelope is infallible")
 }
 
 /// Serialize a single compiled step to deterministic bincode bytes.
 pub fn canonical_bytes_for_step(step: &CompiledStep) -> Vec<u8> {
+    // SAFETY: all fields are primitives, BTreeMaps, Vecs, and Strings.
     bincode::serialize(step).expect("bincode serialization of CompiledStep is infallible")
 }
 
@@ -59,12 +75,16 @@ pub fn canonical_bytes_for_audit(audit: &MacroExpansionAudit) -> Vec<u8> {
 // Content-addressed ID computation
 // ---------------------------------------------------------------------------
 
-/// Compute a content-addressed `CompiledRunbookId` from steps + envelope.
+/// Compute a content-addressed `CompiledRunbookId` from steps + envelope core.
 ///
 /// ```text
-/// SHA-256(bincode(steps) ++ bincode(envelope)) → truncate 128 bits → UUID
+/// SHA-256(bincode(steps) ++ bincode(envelope.core)) → truncate 128 bits → UUID
 /// ```
 ///
+/// Only the deterministic `EnvelopeCore` (no timestamps) feeds into the hash.
+/// This ensures that two compilations of the same input at different times
+/// produce the same `CompiledRunbookId`.
+///
 /// This is the **only** way to derive a `CompiledRunbookId` in production.
 /// `CompiledRunbookId::new()` (random UUID) is retained only for `#[cfg(test)]`.
 pub fn content_addressed_id(
@@ -73,7 +93,7 @@ pub fn content_addressed_id(
 ) -> CompiledRunbookId {
     let mut hasher = Sha256::new();
     hasher.update(canonical_bytes_for_steps(steps));
-    hasher.update(canonical_bytes_for_envelope(envelope));
+    hasher.update(canonical_bytes_for_envelope_core(&envelope.core));
     let hash = hasher.finalize();
 
     // Truncate SHA-256 (32 bytes) to 128 bits (16 bytes) → UUID
@@ -85,12 +105,12 @@ pub fn content_addressed_id(
 
 /// Compute the full SHA-256 hash (32 bytes) for integrity verification.
 ///
-/// Used when storing the canonical hash alongside the JSONB representation
-/// in PostgreSQL — the full hash is stored for tamper detection.
+/// Uses the deterministic `EnvelopeCore` — same hash basis as
+/// `content_addressed_id()` so truncated ID matches full hash prefix.
 pub fn full_sha256(steps: &[CompiledStep], envelope: &ReplayEnvelope) -> [u8; 32] {
     let mut hasher = Sha256::new();
     hasher.update(canonical_bytes_for_steps(steps));
-    hasher.update(canonical_bytes_for_envelope(envelope));
+    hasher.update(canonical_bytes_for_envelope_core(&envelope.core));
     hasher.finalize().into()
 }
 
@@ -125,8 +145,12 @@ mod tests {
         let mut bindings = BTreeMap::new();
         bindings.insert("Allianz".to_string(), Uuid::nil());
         ReplayEnvelope {
-            session_cursor: 42,
-            entity_bindings: bindings,
+            core: super::super::envelope::EnvelopeCore {
+                session_cursor: 42,
+                entity_bindings: bindings,
+                external_lookup_digests: vec![],
+                macro_audit_digests: vec![],
+            },
             external_lookups: vec![],
             macro_audits: vec![],
             sealed_at: chrono::DateTime::UNIX_EPOCH.into(),
@@ -200,12 +224,58 @@ mod tests {
         let steps = vec![sample_step("cbu.create", &[])];
         let env_a = ReplayEnvelope::empty();
         let mut env_b = ReplayEnvelope::empty();
-        env_b.session_cursor = 99;
+        env_b.core.session_cursor = 99;
         let id_a = content_addressed_id(&steps, &env_a);
         let id_b = content_addressed_id(&steps, &env_b);
         assert_ne!(id_a, id_b, "Different envelopes must produce different IDs");
     }
 
+    /// Phase A regression test: same inputs at different times produce same ID.
+    #[test]
+    fn test_timestamp_excluded_from_hash() {
+        let steps = vec![sample_step("cbu.create", &[("name", "Acme")])];
+        let mut env_a = ReplayEnvelope::empty();
+        let mut env_b = ReplayEnvelope::empty();
+        // Different sealed_at timestamps
+        env_a.sealed_at = chrono::DateTime::UNIX_EPOCH.into();
+        env_b.sealed_at = chrono::Utc::now();
+        let id_a = content_addressed_id(&steps, &env_a);
+        let id_b = content_addressed_id(&steps, &env_b);
+        assert_eq!(
+            id_a, id_b,
+            "Timestamps must not affect content-addressed ID"
+        );
+    }
+
+    /// Phase A-3 regression test: compile same input twice, assert identical
+    /// `CompiledRunbookId`. Exercises `CompiledRunbook::new()` which calls
+    /// `content_addressed_id()` internally.
+    #[test]
+    fn test_same_input_same_id() {
+        use crate::runbook::types::CompiledRunbook;
+        let session_id = Uuid::new_v4();
+        let version = 1u64;
+        let steps = vec![sample_step(
+            "cbu.create",
+            &[("name", "Acme"), ("kind", "fund")],
+        )];
+        let env = ReplayEnvelope::with_bindings(
+            42,
+            std::collections::BTreeMap::from([("cbu".to_string(), Uuid::nil())]),
+        );
+
+        let rb1 = CompiledRunbook::new(session_id, version, steps.clone(), env.clone());
+        // Simulate a second compilation at a different time
+        let mut env2 = env;
+        env2.sealed_at = chrono::Utc::now() + chrono::Duration::hours(1);
+        let rb2 = CompiledRunbook::new(session_id, version, steps, env2);
+
+        assert_eq!(
+            rb1.id, rb2.id,
+            "Identical inputs must produce identical CompiledRunbookId regardless of timestamp"
+        );
+    }
+
     // -- Round-trip tests (bincode serialize → deserialize) --
 
     #[test]
@@ -382,29 +452,12 @@ mod proptests {
         ]
     }
 
-    /// Arbitrary JSON values — restricted to `String` only.
-    ///
-    /// `bincode` does not support `deserialize_any()` which `serde_json::Value`
-    /// uses for non-String variants. Since our canonical bytes are used for
-    /// one-way hashing (never deserialized from bincode in production), this
-    /// restriction only affects property test round-trips. String values
-    /// exercise the full serialize→deserialize path.
-    fn arb_json_value() -> impl Strategy<Value = serde_json::Value> {
-        "[a-zA-Z0-9 _-]{0,20}".prop_map(serde_json::Value::String)
-    }
-
     fn arb_btreemap_string_string(
         max_size: usize,
     ) -> impl Strategy<Value = BTreeMap<String, String>> {
         prop::collection::btree_map("[a-z]{1,8}", ".*", 0..max_size)
     }
 
-    fn arb_btreemap_string_json(
-        max_size: usize,
-    ) -> impl Strategy<Value = BTreeMap<String, serde_json::Value>> {
-        prop::collection::btree_map("[a-z]{1,8}", arb_json_value(), 0..max_size)
-    }
-
     // -- Arbitrary types --
 
     fn arb_compiled_step() -> impl Strategy<Value = CompiledStep> {
@@ -456,8 +509,8 @@ mod proptests {
         (
             arb_uuid(),
             "[a-z]+\\.[a-z]+",
-            arb_btreemap_string_json(4),
-            arb_btreemap_string_json(4),
+            arb_btreemap_string_string(4),
+            arb_btreemap_string_string(4),
             "[a-f0-9]{64}",
             arb_expansion_limits(),
             arb_datetime(),
@@ -485,39 +538,52 @@ mod proptests {
             )
     }
 
-    fn arb_replay_envelope() -> impl Strategy<Value = ReplayEnvelope> {
+    fn arb_envelope_core() -> impl Strategy<Value = crate::runbook::envelope::EnvelopeCore> {
         (
             any::<u64>(),
             prop::collection::btree_map("[a-z]{1,8}", arb_uuid(), 0..5),
-            prop::collection::vec(arb_external_lookup(), 0..3),
-            prop::collection::vec(arb_macro_audit(), 0..3),
-            arb_datetime(),
+            prop::collection::vec("[a-f0-9]{64}", 0..3),
+            prop::collection::vec("[a-f0-9]{64}", 0..3),
         )
             .prop_map(
-                |(session_cursor, entity_bindings, external_lookups, macro_audits, sealed_at)| {
-                    ReplayEnvelope {
+                |(
+                    session_cursor,
+                    entity_bindings,
+                    external_lookup_digests,
+                    macro_audit_digests,
+                )| {
+                    crate::runbook::envelope::EnvelopeCore {
                         session_cursor,
                         entity_bindings,
-                        external_lookups,
-                        macro_audits,
-                        sealed_at,
+                        external_lookup_digests,
+                        macro_audit_digests,
                     }
                 },
             )
     }
 
+    fn arb_replay_envelope() -> impl Strategy<Value = ReplayEnvelope> {
+        (
+            arb_envelope_core(),
+            prop::collection::vec(arb_external_lookup(), 0..3),
+            prop::collection::vec(arb_macro_audit(), 0..3),
+            arb_datetime(),
+        )
+            .prop_map(
+                |(core, external_lookups, macro_audits, sealed_at)| ReplayEnvelope {
+                    core,
+                    external_lookups,
+                    macro_audits,
+                    sealed_at,
+                },
+            )
+    }
+
     // -- Property tests (INV-3) --
     //
-    // `CompiledStep` contains no `serde_json::Value` fields, so it supports
-    // full bincode round-trip (serialize → deserialize → equal).
-    //
-    // `MacroExpansionAudit` and `ReplayEnvelope` contain `BTreeMap<String, serde_json::Value>`
-    // for `params` / `resolved_autofill`. bincode serializes `Value` fine, but
-    // `Value::deserialize()` calls `deserialize_any()` which bincode rejects.
-    // This is acceptable: canonical bytes are used for one-way SHA-256 hashing
-    // (INV-2), never deserialized from bincode in production. For these types
-    // we verify **serialization determinism** (same input → same bytes) which
-    // is the property that matters for content-addressed IDs.
+    // All canonical types use only primitives, `BTreeMap<String, String>`,
+    // and `Vec` — fully supported by bincode for round-trip. Every proptest
+    // verifies serialize → deserialize → assert_eq (not just determinism).
 
     proptest! {
         #[test]
@@ -528,25 +594,22 @@ mod proptests {
             prop_assert_eq!(step, decoded);
         }
 
-        /// Serialization determinism for ReplayEnvelope (INV-3).
-        ///
-        /// Verifies that the same envelope always produces identical canonical
-        /// bytes — the property that guarantees content-addressed ID stability.
+        /// Full bincode round-trip for ReplayEnvelope (INV-3).
         #[test]
-        fn replay_envelope_deterministic(env in arb_replay_envelope()) {
-            let bytes1 = canonical_bytes_for_envelope(&env);
-            let bytes2 = canonical_bytes_for_envelope(&env);
-            prop_assert_eq!(bytes1, bytes2,
-                "Same ReplayEnvelope must produce identical canonical bytes");
+        fn replay_envelope_round_trip(env in arb_replay_envelope()) {
+            let bytes = canonical_bytes_for_envelope(&env);
+            let decoded: ReplayEnvelope = bincode::deserialize(&bytes)
+                .expect("bincode round-trip deserialize");
+            prop_assert_eq!(env, decoded);
         }
 
-        /// Serialization determinism for MacroExpansionAudit (INV-3).
+        /// Full bincode round-trip for MacroExpansionAudit (INV-3).
         #[test]
-        fn macro_audit_deterministic(audit in arb_macro_audit()) {
-            let bytes1 = canonical_bytes_for_audit(&audit);
-            let bytes2 = canonical_bytes_for_audit(&audit);
-            prop_assert_eq!(bytes1, bytes2,
-                "Same MacroExpansionAudit must produce identical canonical bytes");
+        fn macro_audit_round_trip(audit in arb_macro_audit()) {
+            let bytes = canonical_bytes_for_audit(&audit);
+            let decoded: MacroExpansionAudit = bincode::deserialize(&bytes)
+                .expect("bincode round-trip deserialize");
+            prop_assert_eq!(audit, decoded);
         }
 
         #[test]
@@ -560,18 +623,21 @@ mod proptests {
         }
     }
 
-    // Non-proptest round-trip tests for ReplayEnvelope and MacroExpansionAudit
-    // using empty JSON maps (no `serde_json::Value` deserialization issues).
+    // Non-proptest round-trip tests with realistic data.
 
     #[test]
-    fn replay_envelope_round_trip_no_json_values() {
+    fn replay_envelope_round_trip_realistic() {
         let env = ReplayEnvelope {
-            session_cursor: 42,
-            entity_bindings: {
-                let mut m = BTreeMap::new();
-                m.insert("allianz".into(), Uuid::new_v4());
-                m.insert("blackrock".into(), Uuid::new_v4());
-                m
+            core: crate::runbook::envelope::EnvelopeCore {
+                session_cursor: 42,
+                entity_bindings: {
+                    let mut m = BTreeMap::new();
+                    m.insert("allianz".into(), Uuid::new_v4());
+                    m.insert("blackrock".into(), Uuid::new_v4());
+                    m
+                },
+                external_lookup_digests: vec!["abc123".into()],
+                macro_audit_digests: vec!["def456".into()],
             },
             external_lookups: vec![ExternalLookup {
                 source: "gleif".into(),
@@ -582,7 +648,7 @@ mod proptests {
             macro_audits: vec![MacroExpansionAudit {
                 expansion_id: Uuid::new_v4(),
                 macro_name: "structure.setup".into(),
-                params: BTreeMap::new(), // empty — avoids serde_json::Value
+                params: BTreeMap::new(),
                 resolved_autofill: BTreeMap::new(),
                 expansion_digest: "def456".into(),
                 expansion_limits: ExpansionLimits::default(),
@@ -597,7 +663,7 @@ mod proptests {
     }
 
     #[test]
-    fn macro_audit_round_trip_no_json_values() {
+    fn macro_audit_round_trip_realistic() {
         let audit = MacroExpansionAudit {
             expansion_id: Uuid::new_v4(),
             macro_name: "party.assign".into(),
@@ -615,4 +681,22 @@ mod proptests {
             bincode::deserialize(&bytes).expect("round-trip with empty JSON maps");
         assert_eq!(audit, decoded);
     }
+
+    #[test]
+    fn envelope_core_round_trip() {
+        let core = crate::runbook::envelope::EnvelopeCore {
+            session_cursor: 99,
+            entity_bindings: {
+                let mut m = BTreeMap::new();
+                m.insert("test".into(), Uuid::new_v4());
+                m
+            },
+            external_lookup_digests: vec!["digest1".into(), "digest2".into()],
+            macro_audit_digests: vec!["macro_digest".into()],
+        };
+        let bytes = canonical_bytes_for_envelope_core(&core);
+        let decoded: crate::runbook::envelope::EnvelopeCore =
+            bincode::deserialize(&bytes).expect("EnvelopeCore round-trip");
+        assert_eq!(core, decoded);
+    }
 }
diff --git a/rust/src/runbook/compiler.rs b/rust/src/runbook/compiler.rs
index 616050d..d4db88c 100644
--- a/rust/src/runbook/compiler.rs
+++ b/rust/src/runbook/compiler.rs
@@ -21,7 +21,7 @@
 //!
 //! Gated behind `vnext-repl` because it depends on `VerbConfigIndex`.
 
-use std::collections::HashMap;
+use std::collections::BTreeMap;
 
 use uuid::Uuid;
 
@@ -83,7 +83,7 @@ use super::verb_classifier::VerbClassification;
 pub fn compile_verb(
     session_id: Uuid,
     classification: &VerbClassification<'_>,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
     macro_registry: &MacroRegistry,
     runbook_version: u64,
@@ -140,7 +140,7 @@ fn compile_macro(
     session_id: Uuid,
     fqn: &str,
     schema: &MacroSchema,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     session: &UnifiedSession,
     macro_registry: &MacroRegistry,
     runbook_version: u64,
@@ -272,10 +272,7 @@ fn compile_macro(
         .map(|a| envelope::MacroExpansionAudit {
             expansion_id: a.expansion_id,
             macro_name: a.macro_fqn.clone(),
-            params: args
-                .iter()
-                .map(|(k, v)| (k.clone(), serde_json::Value::String(v.clone())))
-                .collect(),
+            params: args.iter().map(|(k, v)| (k.clone(), v.clone())).collect(),
             resolved_autofill: std::collections::BTreeMap::new(),
             expansion_digest: a.output_digest.clone(),
             expansion_limits: fixpoint.limits,
@@ -283,9 +280,19 @@ fn compile_macro(
         })
         .collect();
 
+    // Collect deterministic digests for EnvelopeCore (no timestamps).
+    let macro_audit_digests: Vec<String> = macro_audits
+        .iter()
+        .map(|a| a.expansion_digest.clone())
+        .collect();
+
     let envelope = ReplayEnvelope {
-        session_cursor: runbook_version,
-        entity_bindings: std::collections::BTreeMap::new(),
+        core: envelope::EnvelopeCore {
+            session_cursor: runbook_version,
+            entity_bindings: std::collections::BTreeMap::new(),
+            external_lookup_digests: vec![],
+            macro_audit_digests,
+        },
         external_lookups: vec![],
         macro_audits,
         sealed_at: chrono::Utc::now(),
@@ -307,7 +314,7 @@ fn compile_macro(
         compiled_runbook_id: runbook.id,
         runbook_version: runbook.version,
         step_count: runbook.step_count(),
-        envelope_entity_count: runbook.envelope.entity_bindings.len(),
+        envelope_entity_count: runbook.envelope.entity_bindings().len(),
         preview,
         compiled_runbook: Some(runbook),
     })
@@ -325,7 +332,7 @@ fn compile_macro(
 fn compile_primitive(
     session_id: Uuid,
     fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     runbook_version: u64,
     constraints: &EffectiveConstraints,
     sem_reg_allowed_verbs: Option<&std::collections::HashSet<String>>,
@@ -389,7 +396,7 @@ fn compile_primitive(
 /// Find missing required arguments for a macro schema.
 fn find_missing_required_args(
     schema: &MacroSchema,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
 ) -> Vec<MissingField> {
     let mut missing = Vec::new();
 
@@ -433,7 +440,10 @@ fn extract_verb_from_dsl(dsl: &str) -> String {
 }
 
 /// Build a DSL s-expression from verb FQN and args.
-fn build_dsl_from_args(fqn: &str, args: &HashMap<String, String>) -> String {
+///
+/// BTreeMap iteration is deterministic (sorted by key), so no explicit
+/// sorting is needed (INV-2, Phase C).
+fn build_dsl_from_args(fqn: &str, args: &BTreeMap<String, String>) -> String {
     let mut parts = vec![format!("({}", fqn)];
     for (name, value) in args {
         if value.contains(' ') {
@@ -457,7 +467,7 @@ mod tests {
     use crate::repl::verb_config_index::VerbConfigIndex;
     use crate::runbook::verb_classifier::classify_verb;
     use crate::session::unified::{ClientRef, StructureType};
-    use std::collections::HashSet;
+    use std::collections::{HashMap, HashSet};
 
     fn test_session() -> UnifiedSession {
         UnifiedSession {
@@ -547,7 +557,7 @@ mod tests {
         let classification = classify_verb("structure.setup", &verb_index, &registry);
         let constraints = EffectiveConstraints::unconstrained();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Acme Fund".to_string());
 
         let resp = compile_verb(
@@ -577,7 +587,7 @@ mod tests {
         let classification = classify_verb("structure.setup", &verb_index, &registry);
         let constraints = EffectiveConstraints::unconstrained();
 
-        let args = HashMap::new(); // Missing required "name"
+        let args = BTreeMap::new(); // Missing required "name"
 
         let resp = compile_verb(
             Uuid::new_v4(),
@@ -612,7 +622,7 @@ mod tests {
             fqn: "cbu.create".to_string(),
         };
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Test Fund".to_string());
 
         let resp = compile_verb(
@@ -646,7 +656,7 @@ mod tests {
         let resp = compile_verb(
             Uuid::new_v4(),
             &classification,
-            &HashMap::new(),
+            &BTreeMap::new(),
             &session,
             &registry,
             1,
@@ -668,7 +678,7 @@ mod tests {
         let classification = classify_verb("structure.setup", &verb_index, &registry);
         let constraints = EffectiveConstraints::unconstrained();
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Audit Test".to_string());
 
         let resp = compile_verb(
@@ -701,7 +711,7 @@ mod tests {
             contributing_packs: vec![],
         };
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Acme Fund".to_string());
 
         let resp = compile_verb(
@@ -746,7 +756,7 @@ mod tests {
         let resp = compile_verb(
             Uuid::new_v4(),
             &classification,
-            &HashMap::new(),
+            &BTreeMap::new(),
             &session,
             &registry,
             1,
@@ -776,7 +786,7 @@ mod tests {
 
     #[test]
     fn test_build_dsl_from_args() {
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Acme".to_string());
         let dsl = build_dsl_from_args("cbu.create", &args);
         assert!(dsl.starts_with("(cbu.create"));
@@ -792,7 +802,7 @@ mod tests {
     fn test_write_set_derived_from_args() {
         let id1 = Uuid::new_v4();
         let id2 = Uuid::new_v4();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("entity-id".to_string(), id1.to_string());
         args.insert("cbu-id".to_string(), format!("<{}>", id2));
 
@@ -806,7 +816,7 @@ mod tests {
 
     #[test]
     fn test_write_set_ignores_non_uuid_args() {
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Acme Corp".to_string());
         args.insert("jurisdiction".to_string(), "LU".to_string());
         args.insert("count".to_string(), "42".to_string());
@@ -821,7 +831,7 @@ mod tests {
     #[test]
     fn test_write_set_mixed_args() {
         let id = Uuid::new_v4();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("entity-id".to_string(), id.to_string());
         args.insert("name".to_string(), "Test".to_string());
         args.insert("mode".to_string(), "trading".to_string());
@@ -844,7 +854,7 @@ mod tests {
             fqn: "entity.update".to_string(),
         };
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("entity-id".to_string(), entity_id.to_string());
         args.insert("name".to_string(), "Updated Name".to_string());
 
@@ -887,7 +897,7 @@ mod tests {
         let verb_index = VerbConfigIndex::empty();
         let classification = classify_verb("structure.setup", &verb_index, &registry);
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "SemReg Test".to_string());
 
         // SemReg allows only "session.load-galaxy" — the expanded cbu.create will be denied.
@@ -927,7 +937,7 @@ mod tests {
             fqn: "cbu.create".to_string(),
         };
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Denied Fund".to_string());
 
         // Allow only "entity.create" — cbu.create is NOT in the set.
@@ -966,7 +976,7 @@ mod tests {
         let verb_index = VerbConfigIndex::empty();
         let classification = classify_verb("structure.setup", &verb_index, &registry);
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Allowed Fund".to_string());
 
         // Allow the verb that structure.setup expands to.
@@ -999,7 +1009,7 @@ mod tests {
         let verb_index = VerbConfigIndex::empty();
         let classification = classify_verb("structure.setup", &verb_index, &registry);
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Fallback Fund".to_string());
 
         let resp = compile_verb(
@@ -1036,7 +1046,7 @@ mod tests {
         let classification = classify_verb("structure.setup", &verb_index, &registry);
 
         // No args — "name" is required
-        let args = HashMap::new();
+        let args = BTreeMap::new();
 
         let resp = compile_verb(
             Uuid::new_v4(),
@@ -1066,7 +1076,7 @@ mod tests {
         let verb_index = VerbConfigIndex::empty();
         let classification = classify_verb("structure.setup", &verb_index, &registry);
 
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Blocked Fund".to_string());
 
         // Forbid the expanded verb
diff --git a/rust/src/runbook/envelope.rs b/rust/src/runbook/envelope.rs
index 5038b1a..6126605 100644
--- a/rust/src/runbook/envelope.rs
+++ b/rust/src/runbook/envelope.rs
@@ -8,6 +8,13 @@
 //!
 //! Given the same `ReplayEnvelope`, re-executing the compiled runbook must
 //! produce the same sequence of verb calls with the same arguments.
+//!
+//! ## EnvelopeCore vs ReplayEnvelope
+//!
+//! `EnvelopeCore` contains only the deterministic fields that feed into the
+//! content-addressed ID hash. Volatile fields like `sealed_at` and per-audit
+//! timestamps are excluded from the hash input and live only in the full
+//! `ReplayEnvelope` for audit purposes.
 
 use chrono::{DateTime, Utc};
 use serde::{Deserialize, Serialize};
@@ -17,14 +24,16 @@ use uuid::Uuid;
 use crate::dsl_v2::macros::ExpansionLimits;
 
 // ---------------------------------------------------------------------------
-// ReplayEnvelope
+// EnvelopeCore — deterministic hash input (no timestamps)
 // ---------------------------------------------------------------------------
 
-/// Captures the non-deterministic inputs that were resolved at compile time.
+/// The deterministic subset of `ReplayEnvelope` that feeds into the
+/// content-addressed ID hash.
 ///
-/// Stored inside `CompiledRunbook` and never mutated after creation.
+/// Excludes all volatile fields (timestamps) so that two compilations
+/// of the same input at different times produce the same ID.
 #[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
-pub struct ReplayEnvelope {
+pub struct EnvelopeCore {
     /// Session cursor at compilation time (monotonic sequence number).
     pub session_cursor: u64,
 
@@ -36,13 +45,36 @@ pub struct ReplayEnvelope {
     /// Uses `BTreeMap` for deterministic serialization order (INV-2).
     pub entity_bindings: BTreeMap<String, Uuid>,
 
+    /// SHA-256 digests of external lookup responses (deterministic, no timestamps).
+    pub external_lookup_digests: Vec<String>,
+
+    /// SHA-256 digests of macro expansion outputs (deterministic, no timestamps).
+    pub macro_audit_digests: Vec<String>,
+}
+
+// ---------------------------------------------------------------------------
+// ReplayEnvelope
+// ---------------------------------------------------------------------------
+
+/// Captures the non-deterministic inputs that were resolved at compile time.
+///
+/// Stored inside `CompiledRunbook` and never mutated after creation.
+/// The `core` field contains the deterministic subset used for hashing;
+/// the remaining fields are audit metadata (timestamps, full lookup records).
+#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
+pub struct ReplayEnvelope {
+    /// Deterministic core — feeds into content-addressed ID hash.
+    pub core: EnvelopeCore,
+
     /// External lookups performed during compilation (e.g., GLEIF, screening).
+    /// Full records with timestamps for audit trail.
     pub external_lookups: Vec<ExternalLookup>,
 
     /// Macro expansion audits — one per macro expanded during compilation.
+    /// Full records with timestamps for audit trail.
     pub macro_audits: Vec<MacroExpansionAudit>,
 
-    /// When this envelope was sealed.
+    /// When this envelope was sealed (audit only, not hashed).
     pub sealed_at: DateTime<Utc>,
 }
 
@@ -50,8 +82,12 @@ impl ReplayEnvelope {
     /// Create an empty envelope (no external inputs).
     pub fn empty() -> Self {
         Self {
-            session_cursor: 0,
-            entity_bindings: BTreeMap::new(),
+            core: EnvelopeCore {
+                session_cursor: 0,
+                entity_bindings: BTreeMap::new(),
+                external_lookup_digests: Vec::new(),
+                macro_audit_digests: Vec::new(),
+            },
             external_lookups: Vec::new(),
             macro_audits: Vec::new(),
             sealed_at: Utc::now(),
@@ -61,13 +97,27 @@ impl ReplayEnvelope {
     /// Create an envelope with entity bindings.
     pub fn with_bindings(session_cursor: u64, bindings: BTreeMap<String, Uuid>) -> Self {
         Self {
-            session_cursor,
-            entity_bindings: bindings,
+            core: EnvelopeCore {
+                session_cursor,
+                entity_bindings: bindings,
+                external_lookup_digests: Vec::new(),
+                macro_audit_digests: Vec::new(),
+            },
             external_lookups: Vec::new(),
             macro_audits: Vec::new(),
             sealed_at: Utc::now(),
         }
     }
+
+    /// Convenience accessor for session_cursor.
+    pub fn session_cursor(&self) -> u64 {
+        self.core.session_cursor
+    }
+
+    /// Convenience accessor for entity_bindings.
+    pub fn entity_bindings(&self) -> &BTreeMap<String, Uuid> {
+        &self.core.entity_bindings
+    }
 }
 
 // ---------------------------------------------------------------------------
@@ -113,13 +163,16 @@ pub struct MacroExpansionAudit {
 
     /// Parameters supplied to the macro.
     ///
-    /// Uses `BTreeMap` for deterministic serialization order (INV-2).
-    pub params: BTreeMap<String, serde_json::Value>,
+    /// Uses `BTreeMap<String, String>` for deterministic serialization and
+    /// guaranteed bincode round-trip (INV-2). `serde_json::Value` was removed
+    /// because it can carry `f64` (violating no-floats) and bincode's internal
+    /// `Value` encoding is not guaranteed stable across crate versions.
+    pub params: BTreeMap<String, String>,
 
     /// Autofill values that were resolved from session state.
     ///
-    /// Uses `BTreeMap` for deterministic serialization order (INV-2).
-    pub resolved_autofill: BTreeMap<String, serde_json::Value>,
+    /// Uses `BTreeMap<String, String>` for deterministic serialization (INV-2).
+    pub resolved_autofill: BTreeMap<String, String>,
 
     /// SHA-256 digest of the expanded DSL output.
     pub expansion_digest: String,
@@ -147,8 +200,8 @@ mod tests {
         let env = ReplayEnvelope::empty();
         let json = serde_json::to_string(&env).unwrap();
         let back: ReplayEnvelope = serde_json::from_str(&json).unwrap();
-        assert_eq!(back.session_cursor, 0);
-        assert!(back.entity_bindings.is_empty());
+        assert_eq!(back.core.session_cursor, 0);
+        assert!(back.core.entity_bindings.is_empty());
         assert!(back.macro_audits.is_empty());
     }
 
@@ -157,7 +210,16 @@ mod tests {
         let mut bindings = BTreeMap::new();
         bindings.insert("Allianz".into(), Uuid::new_v4());
         let env = ReplayEnvelope::with_bindings(42, bindings.clone());
-        assert_eq!(env.session_cursor, 42);
-        assert_eq!(env.entity_bindings.len(), 1);
+        assert_eq!(env.core.session_cursor, 42);
+        assert_eq!(env.core.entity_bindings.len(), 1);
+    }
+
+    #[test]
+    fn convenience_accessors() {
+        let mut bindings = BTreeMap::new();
+        bindings.insert("Test".into(), Uuid::new_v4());
+        let env = ReplayEnvelope::with_bindings(7, bindings);
+        assert_eq!(env.session_cursor(), 7);
+        assert_eq!(env.entity_bindings().len(), 1);
     }
 }
diff --git a/rust/src/runbook/errors.rs b/rust/src/runbook/errors.rs
index 1a6e97a..5667226 100644
--- a/rust/src/runbook/errors.rs
+++ b/rust/src/runbook/errors.rs
@@ -1,7 +1,8 @@
 //! Typed compilation error model (INV-7).
 //!
 //! Every compilation failure maps to exactly one `CompilationErrorKind` variant.
-//! The 7 variants correspond 1:1 to the 7 phases in §6.2 of the paper:
+//! The 8 variants correspond to the 7 phases in §6.2 of the paper plus a
+//! catch-all for unexpected internal errors:
 //!
 //! ```text
 //! Step 1: expand    → ExpansionFailed | CycleDetected | LimitsExceeded
@@ -11,13 +12,14 @@
 //! Step 5: write_set → (infallible — empty set on failure)
 //! Step 6: store     → StoreFailed
 //! Step 7: envelope  → (infallible — always succeeds)
+//! (internal)        → InternalError (catch-all)
 //! ```
 //!
 //! ## Rules
 //!
 //! - `thiserror` for enum derivation — no manual `Display` impls.
 //! - No `.unwrap()` in this module (INV-7).
-//! - All 7 variants must be constructible (test enforced).
+//! - All 8 variants must be constructible (test enforced).
 
 use serde::{Deserialize, Serialize};
 
@@ -31,6 +33,10 @@ use serde::{Deserialize, Serialize};
 #[error("{kind}")]
 pub struct CompilationError {
     /// Which phase of the §6.2 pipeline failed.
+    ///
+    /// Serialized as `"error_kind"` to avoid clash with `OrchestratorResponse`'s
+    /// `#[serde(tag = "kind")]` discriminant.
+    #[serde(rename = "error_kind")]
     pub kind: CompilationErrorKind,
 
     /// Phase name for telemetry/logging (e.g., `"expand"`, `"dag"`, `"sem_reg"`).
@@ -51,9 +57,9 @@ impl CompilationError {
 // CompilationErrorKind — the 7 §6.2 variants
 // ---------------------------------------------------------------------------
 
-/// All possible compilation failure modes, one per §6.2 phase.
+/// All possible compilation failure modes, one per §6.2 phase plus a catch-all.
 ///
-/// INV-7: exactly 7 variants, all constructible, all `thiserror`-derived.
+/// INV-7: exactly 8 variants, all constructible, all `thiserror`-derived.
 #[derive(Debug, Clone, Serialize, Deserialize, thiserror::Error)]
 #[serde(tag = "error_kind", rename_all = "snake_case")]
 pub enum CompilationErrorKind {
@@ -84,6 +90,11 @@ pub enum CompilationErrorKind {
     /// Storage operation failed (e.g., Postgres insert error).
     #[error("Storage failed: {reason}")]
     StoreFailed { reason: String },
+
+    /// Catch-all for unexpected internal errors (e.g., serialization failure,
+    /// invariant violation). Maps to `source_phase = "internal"`.
+    #[error("Internal error: {reason}")]
+    InternalError { reason: String },
 }
 
 // ---------------------------------------------------------------------------
@@ -94,9 +105,9 @@ pub enum CompilationErrorKind {
 mod tests {
     use super::*;
 
-    /// INV-7: All 7 CompilationErrorKind variants must be constructible.
+    /// INV-7: All 8 CompilationErrorKind variants must be constructible.
     #[test]
-    fn test_all_7_error_kinds_constructible() {
+    fn test_all_8_error_kinds_constructible() {
         let variants: Vec<CompilationErrorKind> = vec![
             CompilationErrorKind::ExpansionFailed {
                 reason: "missing field".into(),
@@ -121,9 +132,12 @@ mod tests {
             CompilationErrorKind::StoreFailed {
                 reason: "connection refused".into(),
             },
+            CompilationErrorKind::InternalError {
+                reason: "unexpected serialization failure".into(),
+            },
         ];
 
-        assert_eq!(variants.len(), 7, "Must have exactly 7 variants (INV-7)");
+        assert_eq!(variants.len(), 8, "Must have exactly 8 variants (INV-7)");
 
         // Each variant produces a non-empty Display string
         for v in &variants {
@@ -145,6 +159,58 @@ mod tests {
         assert!(msg.contains("A → B → A"));
     }
 
+    /// INV-7: No `.unwrap()` in non-test runbook code.
+    ///
+    /// Static grep test — scans all `runbook/*.rs` files for `.unwrap()` calls
+    /// outside of `#[cfg(test)]` / `#[test]` blocks. `.expect()` is allowed
+    /// (provides context on panic).
+    #[test]
+    fn test_no_unwrap_in_runbook_module() {
+        use std::fs;
+        use std::path::Path;
+
+        let runbook_dir = Path::new(env!("CARGO_MANIFEST_DIR")).join("src/runbook");
+        let mut violations = Vec::new();
+
+        for entry in fs::read_dir(&runbook_dir).expect("read runbook dir") {
+            let entry = entry.expect("dir entry");
+            let path = entry.path();
+            if path.extension().map_or(true, |e| e != "rs") {
+                continue;
+            }
+
+            let source = fs::read_to_string(&path).expect("read file");
+            let filename = path.file_name().expect("filename").to_string_lossy();
+
+            let mut in_test_block = false;
+            for (line_no, line) in source.lines().enumerate() {
+                let trimmed = line.trim();
+
+                // Track #[cfg(test)] mod blocks
+                if trimmed == "#[cfg(test)]"
+                    || trimmed.starts_with("#[test]")
+                    || trimmed.starts_with("#[tokio::test")
+                {
+                    in_test_block = true;
+                }
+
+                // Skip comments and string literals mentioning .unwrap()
+                let is_comment = trimmed.starts_with("//")
+                    || trimmed.starts_with("///")
+                    || trimmed.starts_with("//!");
+                if !in_test_block && !is_comment && trimmed.contains(".unwrap()") {
+                    violations.push(format!("  {}:{}: {}", filename, line_no + 1, trimmed));
+                }
+            }
+        }
+
+        assert!(
+            violations.is_empty(),
+            "INV-7: Found .unwrap() in non-test runbook code:\n{}",
+            violations.join("\n")
+        );
+    }
+
     #[test]
     fn test_compilation_error_serde_round_trip() {
         let err = CompilationError::new(
diff --git a/rust/src/runbook/executor.rs b/rust/src/runbook/executor.rs
index 2d9e7ba..9a36678 100644
--- a/rust/src/runbook/executor.rs
+++ b/rust/src/runbook/executor.rs
@@ -92,6 +92,22 @@ pub enum ExecutionError {
     LockContention {
         entity_type: String,
         entity_id: String,
+        /// Best-effort holder of the contested lock (INV-10).
+        holder_runbook_id: Option<uuid::Uuid>,
+    },
+
+    /// Lock acquisition timed out (INV-10: 30s timeout).
+    ///
+    /// Carries the full write_set and all entity IDs that could not be locked,
+    /// plus best-effort holder identification.
+    #[error("Lock timeout on {} entities (write_set size: {})", entity_ids.len(), write_set.len())]
+    LockTimeout {
+        /// Entity UUIDs that could not be locked.
+        entity_ids: Vec<Uuid>,
+        /// Full write_set that was requested.
+        write_set: std::collections::BTreeSet<Uuid>,
+        /// Best-effort: the runbook currently holding the contested lock.
+        holder_runbook_id: Option<CompiledRunbookId>,
     },
 
     #[error("Database error: {0}")]
@@ -123,12 +139,19 @@ impl RunbookStore {
     /// Store a compiled runbook.
     pub fn insert(&self, runbook: CompiledRunbook) {
         let id = runbook.id;
-        self.runbooks.write().unwrap().insert(id, runbook);
+        self.runbooks
+            .write()
+            .expect("RunbookStore RwLock poisoned")
+            .insert(id, runbook);
     }
 
     /// Retrieve a compiled runbook by ID.
     pub fn get(&self, id: &CompiledRunbookId) -> Option<CompiledRunbook> {
-        self.runbooks.read().unwrap().get(id).cloned()
+        self.runbooks
+            .read()
+            .expect("RunbookStore RwLock poisoned")
+            .get(id)
+            .cloned()
     }
 
     /// Update the status of a compiled runbook.
@@ -137,7 +160,7 @@ impl RunbookStore {
         id: &CompiledRunbookId,
         status: CompiledRunbookStatus,
     ) -> Result<(), ExecutionError> {
-        let mut map = self.runbooks.write().unwrap();
+        let mut map = self.runbooks.write().expect("RunbookStore RwLock poisoned");
         let rb = map.get_mut(id).ok_or(ExecutionError::NotFound(*id))?;
         rb.status = status;
         Ok(())
@@ -150,6 +173,99 @@ impl Default for RunbookStore {
     }
 }
 
+// ---------------------------------------------------------------------------
+// RunbookStoreBackend — unified trait for compiled runbook stores (INV-9)
+// ---------------------------------------------------------------------------
+
+/// Unified store trait for compiled runbooks (INV-9).
+///
+/// Both in-memory (dev/test) and Postgres (prod) backends implement this.
+/// The executor accepts `&dyn RunbookStoreBackend` — one path, one trait.
+#[async_trait::async_trait]
+pub trait RunbookStoreBackend: Send + Sync {
+    /// Insert a compiled runbook. Content-addressed dedup: same ID = no-op.
+    async fn insert(&self, runbook: &CompiledRunbook) -> Result<(), ExecutionError>;
+
+    /// Retrieve a compiled runbook by ID. Returns None if not found.
+    async fn get(&self, id: &CompiledRunbookId) -> Result<Option<CompiledRunbook>, ExecutionError>;
+
+    /// Append an event to the audit log (INSERT-only).
+    async fn append_event(&self, event: RunbookEvent) -> Result<(), ExecutionError>;
+
+    /// Derive current status from the latest status_change event.
+    async fn current_status(
+        &self,
+        id: &CompiledRunbookId,
+    ) -> Result<CompiledRunbookStatus, ExecutionError>;
+
+    /// Update status (in-memory impl mutates; Postgres impl appends status_change event).
+    async fn update_status(
+        &self,
+        id: &CompiledRunbookId,
+        old_status: &str,
+        new_status: CompiledRunbookStatus,
+    ) -> Result<(), ExecutionError>;
+
+    /// Best-effort lookup of which runbook holds a lock on the given entity.
+    async fn lookup_lock_holder(&self, entity_type: &str, entity_id: &str) -> Option<Uuid>;
+}
+
+// ---------------------------------------------------------------------------
+// RunbookStoreBackend impl for RunbookStore (in-memory)
+// ---------------------------------------------------------------------------
+
+#[async_trait::async_trait]
+impl RunbookStoreBackend for RunbookStore {
+    async fn insert(&self, runbook: &CompiledRunbook) -> Result<(), ExecutionError> {
+        let id = runbook.id;
+        self.runbooks
+            .write()
+            .expect("RunbookStore RwLock poisoned")
+            .insert(id, runbook.clone());
+        Ok(())
+    }
+
+    async fn get(&self, id: &CompiledRunbookId) -> Result<Option<CompiledRunbook>, ExecutionError> {
+        Ok(self
+            .runbooks
+            .read()
+            .expect("RunbookStore RwLock poisoned")
+            .get(id)
+            .cloned())
+    }
+
+    async fn append_event(&self, _event: RunbookEvent) -> Result<(), ExecutionError> {
+        // In-memory store has no event log — no-op.
+        Ok(())
+    }
+
+    async fn current_status(
+        &self,
+        id: &CompiledRunbookId,
+    ) -> Result<CompiledRunbookStatus, ExecutionError> {
+        let map = self.runbooks.read().expect("RunbookStore RwLock poisoned");
+        let rb = map.get(id).ok_or(ExecutionError::NotFound(*id))?;
+        Ok(rb.status.clone())
+    }
+
+    async fn update_status(
+        &self,
+        id: &CompiledRunbookId,
+        _old_status: &str,
+        new_status: CompiledRunbookStatus,
+    ) -> Result<(), ExecutionError> {
+        let mut map = self.runbooks.write().expect("RunbookStore RwLock poisoned");
+        let rb = map.get_mut(id).ok_or(ExecutionError::NotFound(*id))?;
+        rb.status = new_status;
+        Ok(())
+    }
+
+    async fn lookup_lock_holder(&self, _entity_type: &str, _entity_id: &str) -> Option<Uuid> {
+        // In-memory store has no event log to query.
+        None
+    }
+}
+
 // ---------------------------------------------------------------------------
 // RunbookEvent — event log entry for compiled_runbook_events (INV-9)
 // ---------------------------------------------------------------------------
@@ -336,6 +452,95 @@ impl PostgresRunbookStore {
             _ => Ok(CompiledRunbookStatus::Compiled),
         }
     }
+
+    /// Best-effort lookup for the compiled runbook currently holding a lock on an entity.
+    ///
+    /// Queries `compiled_runbook_events` for the most recent `lock_acquired` event
+    /// whose `detail` JSON contains the contested entity in its write_set, and which
+    /// has no subsequent `lock_released` event for the same runbook.
+    ///
+    /// Returns `None` on any error or if no holder is found (advisory locks are
+    /// anonymous in PostgreSQL — this is a heuristic).
+    pub async fn lookup_lock_holder(&self, entity_type: &str, entity_id: &str) -> Option<Uuid> {
+        // Suppress unused-variable warnings when feature is enabled but
+        // the query references them via bind parameters.
+        let _ = entity_type;
+
+        // Find the most recent lock_acquired event where write_set contains
+        // the contested entity_id and no corresponding lock_released follows.
+        let row: Option<(Uuid,)> = sqlx::query_as(
+            r#"
+            SELECT a.compiled_runbook_id
+            FROM "ob-poc".compiled_runbook_events a
+            WHERE a.event_type = 'lock_acquired'
+              AND a.detail @> $1::jsonb
+              AND NOT EXISTS (
+                  SELECT 1
+                  FROM "ob-poc".compiled_runbook_events r
+                  WHERE r.compiled_runbook_id = a.compiled_runbook_id
+                    AND r.event_type = 'lock_released'
+                    AND r.created_at > a.created_at
+              )
+            ORDER BY a.created_at DESC
+            LIMIT 1
+            "#,
+        )
+        .bind(serde_json::json!({ "write_set": [entity_id] }))
+        .fetch_optional(&self.pool)
+        .await
+        .ok()
+        .flatten();
+
+        row.map(|(id,)| id)
+    }
+}
+
+// ---------------------------------------------------------------------------
+// RunbookStoreBackend impl for PostgresRunbookStore (INV-9)
+// ---------------------------------------------------------------------------
+
+#[cfg(feature = "database")]
+#[async_trait::async_trait]
+impl RunbookStoreBackend for PostgresRunbookStore {
+    async fn insert(&self, runbook: &CompiledRunbook) -> Result<(), ExecutionError> {
+        PostgresRunbookStore::insert(self, runbook).await
+    }
+
+    async fn get(&self, id: &CompiledRunbookId) -> Result<Option<CompiledRunbook>, ExecutionError> {
+        PostgresRunbookStore::get(self, id).await
+    }
+
+    async fn append_event(&self, event: RunbookEvent) -> Result<(), ExecutionError> {
+        PostgresRunbookStore::append_event(self, event).await
+    }
+
+    async fn current_status(
+        &self,
+        id: &CompiledRunbookId,
+    ) -> Result<CompiledRunbookStatus, ExecutionError> {
+        PostgresRunbookStore::current_status(self, id).await
+    }
+
+    async fn update_status(
+        &self,
+        id: &CompiledRunbookId,
+        old_status: &str,
+        new_status: CompiledRunbookStatus,
+    ) -> Result<(), ExecutionError> {
+        // Append-only: status is tracked via events, never mutated on the row.
+        self.append_event(RunbookEvent {
+            compiled_runbook_id: *id,
+            event_type: "status_change".into(),
+            old_status: Some(old_status.to_string()),
+            new_status: Some(status_to_string(&new_status).to_string()),
+            detail: status_detail(&new_status),
+        })
+        .await
+    }
+
+    async fn lookup_lock_holder(&self, entity_type: &str, entity_id: &str) -> Option<Uuid> {
+        PostgresRunbookStore::lookup_lock_holder(self, entity_type, entity_id).await
+    }
 }
 
 /// Row type for compiled_runbooks table queries.
@@ -496,7 +701,7 @@ pub fn compute_write_set(steps: &[CompiledStep], cursor: Option<&StepCursor>) ->
 /// Acquire advisory locks on the write_set using `try_advisory_xact_lock` (fail-fast).
 ///
 /// Locks are acquired in sorted UUID order to prevent deadlocks. On contention,
-/// returns `ExecutionError::LockContention` immediately — no blocking.
+/// returns `ExecutionError::LockTimeout` with the full write_set and holder info (INV-10).
 ///
 /// Returns the open transaction that holds the locks. The caller MUST keep this
 /// transaction alive during step execution and commit/rollback when done.
@@ -504,6 +709,7 @@ pub fn compute_write_set(steps: &[CompiledStep], cursor: Option<&StepCursor>) ->
 async fn acquire_advisory_locks(
     pool: &sqlx::PgPool,
     write_set: &BTreeSet<Uuid>,
+    store: &dyn RunbookStoreBackend,
 ) -> Result<(sqlx::Transaction<'static, sqlx::Postgres>, LockStats), ExecutionError> {
     use crate::database::locks::{acquire_locks, LockError, LockKey, LockMode};
 
@@ -537,13 +743,28 @@ async fn acquire_advisory_locks(
         Err(LockError::Contention {
             entity_type,
             entity_id,
+            holder_runbook_id,
             ..
         }) => {
-            // Fail-fast: roll back and surface contention error.
+            // Roll back and surface timeout error with full write_set (INV-10).
             let _ = tx.rollback().await;
-            Err(ExecutionError::LockContention {
-                entity_type,
-                entity_id,
+
+            // Attempt holder lookup via store if not already known.
+            let holder = if holder_runbook_id.is_some() {
+                holder_runbook_id.map(CompiledRunbookId)
+            } else {
+                store
+                    .lookup_lock_holder(&entity_type, &entity_id)
+                    .await
+                    .map(CompiledRunbookId)
+            };
+
+            let entity_uuid = Uuid::parse_str(&entity_id).unwrap_or(Uuid::nil());
+
+            Err(ExecutionError::LockTimeout {
+                entity_ids: vec![entity_uuid],
+                write_set: write_set.clone(),
+                holder_runbook_id: holder,
             })
         }
         Err(LockError::Database(e)) => {
@@ -579,12 +800,12 @@ async fn acquire_advisory_locks(
 /// In Phase 0 (no database), locking is skipped and execution proceeds
 /// directly.
 pub async fn execute_runbook(
-    store: &RunbookStore,
+    store: &dyn RunbookStoreBackend,
     runbook_id: CompiledRunbookId,
     cursor: Option<StepCursor>,
     executor: &dyn StepExecutor,
 ) -> Result<RunbookExecutionResult, ExecutionError> {
-    execute_runbook_with_pool(store, runbook_id, cursor, executor, None, None).await
+    execute_runbook_with_pool(store, runbook_id, cursor, executor, None).await
 }
 
 /// Execute a compiled runbook with optional advisory locking.
@@ -595,23 +816,22 @@ pub async fn execute_runbook(
 ///
 /// When `pool` is `None` (tests, in-memory mode), locking is skipped.
 ///
-/// When `pg_store` is `Some`, lock acquire/release/contention events are logged
-/// to `compiled_runbook_events` (INV-10).
-#[allow(clippy::too_many_arguments)]
+/// The store backend handles event emission: the Postgres backend appends
+/// status_change events on `update_status()` and persists lock/step events
+/// via `append_event()`. The in-memory backend no-ops on events.
 pub async fn execute_runbook_with_pool(
-    store: &RunbookStore,
+    store: &dyn RunbookStoreBackend,
     runbook_id: CompiledRunbookId,
     cursor: Option<StepCursor>,
     executor: &dyn StepExecutor,
     pool: Option<&sqlx::PgPool>,
-    #[cfg(feature = "database")] pg_store: Option<&PostgresRunbookStore>,
-    #[cfg(not(feature = "database"))] _pg_store: Option<&()>,
 ) -> Result<RunbookExecutionResult, ExecutionError> {
     let start = std::time::Instant::now();
 
     // 1. Look up runbook
     let runbook = store
         .get(&runbook_id)
+        .await?
         .ok_or(ExecutionError::NotFound(runbook_id))?;
 
     // 2. Validate status
@@ -634,37 +854,33 @@ pub async fn execute_runbook_with_pool(
     // This makes locking real (Fix 2): locks cover the entire execution window.
     let (_lock_tx, lock_stats) = if !write_set.is_empty() {
         if let Some(pool) = pool {
-            let result = acquire_advisory_locks(pool, &write_set).await;
+            let result = acquire_advisory_locks(pool, &write_set, store).await;
 
             // Log lock contention event (INV-10)
-            #[cfg(feature = "database")]
-            if let Err(ExecutionError::LockContention {
-                ref entity_type,
-                ref entity_id,
+            if let Err(ExecutionError::LockTimeout {
+                ref entity_ids,
+                ref write_set,
+                ref holder_runbook_id,
             }) = result
             {
-                if let Some(pg) = pg_store {
-                    let _ = pg.append_event(RunbookEvent {
+                let _ = store.append_event(RunbookEvent {
                         compiled_runbook_id: runbook_id,
                         event_type: "lock_contention".into(),
                         old_status: None,
                         new_status: None,
                         detail: Some(serde_json::json!({
-                            "entity_type": entity_type,
-                            "entity_id": entity_id,
+                            "entity_ids": entity_ids.iter().map(|id| id.to_string()).collect::<Vec<_>>(),
                             "write_set": write_set.iter().map(|id| id.to_string()).collect::<Vec<_>>(),
-                            "holder_runbook_id": null,
+                            "holder_runbook_id": holder_runbook_id.map(|h| h.0.to_string()),
                         })),
                     }).await;
-                }
             }
 
             let (tx, stats) = result?;
 
             // Log lock_acquired event (INV-10)
-            #[cfg(feature = "database")]
-            if let Some(pg) = pg_store {
-                let _ = pg.append_event(RunbookEvent {
+            let _ = store
+                .append_event(RunbookEvent {
                     compiled_runbook_id: runbook_id,
                     event_type: "lock_acquired".into(),
                     old_status: None,
@@ -674,8 +890,8 @@ pub async fn execute_runbook_with_pool(
                         "lock_wait_ms": stats.lock_wait_ms,
                         "write_set": write_set.iter().map(|id| id.to_string()).collect::<Vec<_>>(),
                     })),
-                }).await;
-            }
+                })
+                .await;
 
             (Some(tx), stats)
         } else {
@@ -699,12 +915,15 @@ pub async fn execute_runbook_with_pool(
     };
 
     // 4. Transition to Executing — only AFTER locks are acquired.
-    store.update_status(
-        &runbook_id,
-        CompiledRunbookStatus::Executing {
-            current_step: start_idx,
-        },
-    )?;
+    store
+        .update_status(
+            &runbook_id,
+            "compiled",
+            CompiledRunbookStatus::Executing {
+                current_step: start_idx,
+            },
+        )
+        .await?;
 
     // 5. Execute steps (advisory locks held via `_lock_tx` throughout)
     let mut step_results = Vec::with_capacity(runbook.steps.len());
@@ -735,6 +954,21 @@ pub async fn execute_runbook_with_pool(
 
         if dep_failed {
             failed_steps.insert(step.step_id);
+            // Emit step_skipped event (INV-9, Phase E-2)
+            let _ = store
+                .append_event(RunbookEvent {
+                    compiled_runbook_id: runbook_id,
+                    event_type: "step_skipped".into(),
+                    old_status: None,
+                    new_status: None,
+                    detail: Some(serde_json::json!({
+                        "step_id": step.step_id.to_string(),
+                        "verb": &step.verb,
+                        "step_index": idx,
+                        "reason": "Dependency failed",
+                    })),
+                })
+                .await;
             step_results.push(StepExecutionResult {
                 step_id: step.step_id,
                 verb: step.verb.clone(),
@@ -746,14 +980,38 @@ pub async fn execute_runbook_with_pool(
         }
 
         // Update current step
-        store.update_status(
-            &runbook_id,
-            CompiledRunbookStatus::Executing { current_step: idx },
-        )?;
+        store
+            .update_status(
+                &runbook_id,
+                "executing",
+                CompiledRunbookStatus::Executing { current_step: idx },
+            )
+            .await?;
 
         // Execute the step
         let outcome = executor.execute_step(step).await;
 
+        // Emit per-step event (INV-9, Phase E-2)
+        let step_event_type = match &outcome {
+            StepOutcome::Completed { .. } => "step_completed",
+            StepOutcome::Failed { .. } => "step_failed",
+            StepOutcome::Parked { .. } => "step_parked",
+            StepOutcome::Skipped { .. } => "step_skipped",
+        };
+        let _ = store
+            .append_event(RunbookEvent {
+                compiled_runbook_id: runbook_id,
+                event_type: step_event_type.into(),
+                old_status: None,
+                new_status: None,
+                detail: Some(serde_json::json!({
+                    "step_id": step.step_id.to_string(),
+                    "verb": &step.verb,
+                    "step_index": idx,
+                })),
+            })
+            .await;
+
         // Determine whether this step terminates the runbook loop
         let should_break = match &outcome {
             StepOutcome::Parked {
@@ -792,7 +1050,22 @@ pub async fn execute_runbook_with_pool(
 
         if let Some(skip_reason) = should_break {
             // Fill remaining steps as skipped
-            for remaining in runbook.steps.iter().skip(idx + 1) {
+            for (rem_idx, remaining) in runbook.steps.iter().enumerate().skip(idx + 1) {
+                // Emit step_skipped event for remaining steps (INV-9, Phase E-2)
+                let _ = store
+                    .append_event(RunbookEvent {
+                        compiled_runbook_id: runbook_id,
+                        event_type: "step_skipped".into(),
+                        old_status: None,
+                        new_status: None,
+                        detail: Some(serde_json::json!({
+                            "step_id": remaining.step_id.to_string(),
+                            "verb": &remaining.verb,
+                            "step_index": rem_idx,
+                            "reason": skip_reason,
+                        })),
+                    })
+                    .await;
                 step_results.push(StepExecutionResult {
                     step_id: remaining.step_id,
                     verb: remaining.verb.clone(),
@@ -806,7 +1079,9 @@ pub async fn execute_runbook_with_pool(
     }
 
     // 6. Update final status
-    store.update_status(&runbook_id, final_status.clone())?;
+    store
+        .update_status(&runbook_id, "executing", final_status.clone())
+        .await?;
 
     // 7. Release advisory locks by committing (or dropping) the lock transaction.
     //    On success we commit; on any error path above we return early and _lock_tx
@@ -815,21 +1090,18 @@ pub async fn execute_runbook_with_pool(
         let _ = lock_tx.commit().await;
 
         // Log lock_released event (INV-10)
-        #[cfg(feature = "database")]
-        if let Some(pg) = pg_store {
-            let _ = pg
-                .append_event(RunbookEvent {
-                    compiled_runbook_id: runbook_id,
-                    event_type: "lock_released".into(),
-                    old_status: None,
-                    new_status: None,
-                    detail: Some(serde_json::json!({
-                        "locks_released": lock_stats.locks_acquired,
-                        "total_execution_ms": start.elapsed().as_millis() as u64,
-                    })),
-                })
-                .await;
-        }
+        let _ = store
+            .append_event(RunbookEvent {
+                compiled_runbook_id: runbook_id,
+                event_type: "lock_released".into(),
+                old_status: None,
+                new_status: None,
+                detail: Some(serde_json::json!({
+                    "locks_released": lock_stats.locks_acquired,
+                    "total_execution_ms": start.elapsed().as_millis() as u64,
+                })),
+            })
+            .await;
     }
 
     let elapsed_ms = start.elapsed().as_millis() as u64;
@@ -1226,7 +1498,7 @@ mod tests {
         let id1 = Uuid::new_v4();
         let id2 = Uuid::new_v4();
 
-        let mut args = std::collections::HashMap::new();
+        let mut args = std::collections::BTreeMap::new();
         args.insert("entity-id".to_string(), id1.to_string());
         args.insert("cbu-id".to_string(), format!("<{}>", id2));
         args.insert("name".to_string(), "not-a-uuid".to_string());
@@ -1246,7 +1518,7 @@ mod tests {
     fn test_derive_write_set_ignores_non_uuids() {
         use crate::runbook::write_set::derive_write_set;
 
-        let args = std::collections::HashMap::new();
+        let args = std::collections::BTreeMap::new();
 
         let ws: Vec<Uuid> = derive_write_set("test.verb", &args, None)
             .into_iter()
@@ -1389,6 +1661,170 @@ mod tests {
         );
     }
 
+    // -----------------------------------------------------------------------
+    // EventCapturingStore — test backend for asserting event emission (E-4)
+    // -----------------------------------------------------------------------
+
+    /// Test backend that delegates to `RunbookStore` for storage but captures
+    /// all `append_event` calls in a `Vec<RunbookEvent>` behind a `Mutex`.
+    struct EventCapturingStore {
+        inner: RunbookStore,
+        events: std::sync::Mutex<Vec<RunbookEvent>>,
+    }
+
+    impl EventCapturingStore {
+        fn new() -> Self {
+            Self {
+                inner: RunbookStore::new(),
+                events: std::sync::Mutex::new(Vec::new()),
+            }
+        }
+
+        fn captured_events(&self) -> Vec<RunbookEvent> {
+            self.events.lock().expect("events Mutex poisoned").clone()
+        }
+    }
+
+    #[async_trait::async_trait]
+    impl RunbookStoreBackend for EventCapturingStore {
+        async fn insert(&self, runbook: &CompiledRunbook) -> Result<(), ExecutionError> {
+            RunbookStoreBackend::insert(&self.inner, runbook).await
+        }
+
+        async fn get(
+            &self,
+            id: &CompiledRunbookId,
+        ) -> Result<Option<CompiledRunbook>, ExecutionError> {
+            RunbookStoreBackend::get(&self.inner, id).await
+        }
+
+        async fn append_event(&self, event: RunbookEvent) -> Result<(), ExecutionError> {
+            self.events
+                .lock()
+                .expect("events Mutex poisoned")
+                .push(event);
+            Ok(())
+        }
+
+        async fn current_status(
+            &self,
+            id: &CompiledRunbookId,
+        ) -> Result<CompiledRunbookStatus, ExecutionError> {
+            RunbookStoreBackend::current_status(&self.inner, id).await
+        }
+
+        async fn update_status(
+            &self,
+            id: &CompiledRunbookId,
+            old_status: &str,
+            new_status: CompiledRunbookStatus,
+        ) -> Result<(), ExecutionError> {
+            // Capture the status_change event AND delegate to inner for mutation
+            self.append_event(RunbookEvent {
+                compiled_runbook_id: *id,
+                event_type: "status_change".into(),
+                old_status: Some(old_status.to_string()),
+                new_status: Some(format!("{:?}", new_status)),
+                detail: None,
+            })
+            .await?;
+            RunbookStoreBackend::update_status(&self.inner, id, old_status, new_status).await
+        }
+
+        async fn lookup_lock_holder(&self, _entity_type: &str, _entity_id: &str) -> Option<Uuid> {
+            None
+        }
+    }
+
+    /// Phase E-4: Verify event emission for a 3-step execution.
+    ///
+    /// Expected events (no pool = no locks):
+    /// - 1× status_change (compiled → executing)
+    /// - 3× step_completed
+    /// - 1× status_change (executing → completed)
+    /// = 5 events minimum
+    #[tokio::test]
+    async fn test_event_emission_count() {
+        let store = EventCapturingStore::new();
+        let steps = vec![
+            make_step("cbu.create"),
+            make_step("entity.create"),
+            make_step("trading-profile.create"),
+        ];
+        let rb = CompiledRunbook::new(Uuid::new_v4(), 1, steps, ReplayEnvelope::empty());
+        let id = rb.id;
+        store.insert(&rb).await.unwrap();
+
+        let result = execute_runbook(&store, id, None, &SuccessExecutor)
+            .await
+            .unwrap();
+        assert!(matches!(
+            result.final_status,
+            CompiledRunbookStatus::Completed { .. }
+        ));
+
+        let events = store.captured_events();
+
+        // Must have at least 5 events: 2 status_change + 3 step_completed
+        assert!(
+            events.len() >= 5,
+            "Expected ≥5 events for 3-step execution, got {}: {:?}",
+            events.len(),
+            events.iter().map(|e| &e.event_type).collect::<Vec<_>>()
+        );
+
+        // Count by type
+        let status_changes = events
+            .iter()
+            .filter(|e| e.event_type == "status_change")
+            .count();
+        let step_completed = events
+            .iter()
+            .filter(|e| e.event_type == "step_completed")
+            .count();
+
+        assert!(
+            status_changes >= 2,
+            "Expected ≥2 status_change events, got {}",
+            status_changes
+        );
+        assert_eq!(
+            step_completed, 3,
+            "Expected exactly 3 step_completed events, got {}",
+            step_completed
+        );
+    }
+
+    /// Phase E-4: Verify step_failed event is emitted on failure.
+    #[tokio::test]
+    async fn test_event_emission_on_failure() {
+        let store = EventCapturingStore::new();
+        let steps = vec![make_step("cbu.create"), make_step("entity.create")];
+        let rb = CompiledRunbook::new(Uuid::new_v4(), 1, steps, ReplayEnvelope::empty());
+        let id = rb.id;
+        store.insert(&rb).await.unwrap();
+
+        let executor = FailOnVerb("cbu.create".into());
+        let result = execute_runbook(&store, id, None, &executor).await.unwrap();
+        assert!(matches!(
+            result.final_status,
+            CompiledRunbookStatus::Failed { .. }
+        ));
+
+        let events = store.captured_events();
+        let step_failed = events
+            .iter()
+            .filter(|e| e.event_type == "step_failed")
+            .count();
+        let step_skipped = events
+            .iter()
+            .filter(|e| e.event_type == "step_skipped")
+            .count();
+
+        assert_eq!(step_failed, 1, "Expected 1 step_failed event");
+        assert_eq!(step_skipped, 1, "Expected 1 step_skipped event");
+    }
+
     /// INV-10: Lock events must be logged in `execute_runbook_with_pool()`.
     ///
     /// Static grep verifying that lock_acquired, lock_released, and lock_contention
diff --git a/rust/src/runbook/mod.rs b/rust/src/runbook/mod.rs
index 86cf2cc..face5cd 100644
--- a/rust/src/runbook/mod.rs
+++ b/rust/src/runbook/mod.rs
@@ -49,20 +49,20 @@ pub mod write_set;
 
 // Re-export key types at module boundary
 pub use canonical::{
-    canonical_bytes_for_envelope, canonical_bytes_for_step, canonical_bytes_for_steps,
-    content_addressed_id, full_sha256,
+    canonical_bytes_for_envelope, canonical_bytes_for_envelope_core, canonical_bytes_for_step,
+    canonical_bytes_for_steps, content_addressed_id, full_sha256,
 };
 #[cfg(feature = "vnext-repl")]
 pub use compiler::compile_verb;
 #[cfg(feature = "vnext-repl")]
 pub use constraint_gate::check_pack_constraints;
-pub use envelope::ReplayEnvelope;
+pub use envelope::{EnvelopeCore, ReplayEnvelope};
 pub use errors::{CompilationError, CompilationErrorKind};
 #[cfg(feature = "database")]
 pub use executor::PostgresRunbookStore;
 pub use executor::{
     execute_runbook, ExecutionError, LockStats, RunbookEvent, RunbookExecutionResult, RunbookStore,
-    StepExecutionResult, StepExecutor, StepOutcome,
+    RunbookStoreBackend, StepExecutionResult, StepExecutor, StepOutcome,
 };
 pub use response::{
     ClarificationContext, ClarificationRequest, CompiledRunbookSummary, ConstraintViolationDetail,
@@ -112,7 +112,7 @@ pub use verb_classifier::{classify_verb, VerbClassification};
 pub fn compile_invocation(
     session_id: uuid::Uuid,
     verb_fqn: &str,
-    args: &std::collections::HashMap<String, String>,
+    args: &std::collections::BTreeMap<String, String>,
     session: &crate::session::unified::UnifiedSession,
     macro_registry: &crate::dsl_v2::macros::MacroRegistry,
     verb_config_index: &crate::repl::verb_config_index::VerbConfigIndex,
@@ -157,7 +157,7 @@ mod tests {
         let resp = compile_invocation(
             uuid::Uuid::new_v4(),
             "nonexistent.verb",
-            &std::collections::HashMap::new(),
+            &std::collections::BTreeMap::new(),
             &session,
             &macro_reg,
             &verb_index,
@@ -186,7 +186,7 @@ mod tests {
         let resp = compile_invocation(
             uuid::Uuid::new_v4(),
             "cbu.create",
-            &std::collections::HashMap::new(),
+            &std::collections::BTreeMap::new(),
             &UnifiedSession::new(),
             &MacroRegistry::new(),
             &VerbConfigIndex::empty(),
diff --git a/rust/src/runbook/response.rs b/rust/src/runbook/response.rs
index aa729b0..4553a0f 100644
--- a/rust/src/runbook/response.rs
+++ b/rust/src/runbook/response.rs
@@ -27,6 +27,7 @@ use super::types::{CompiledRunbook, CompiledRunbookId};
 /// MCP) pattern-matches to decide what to show the user.
 #[derive(Debug, Clone, Serialize, Deserialize)]
 #[serde(tag = "kind", rename_all = "snake_case")]
+#[allow(clippy::large_enum_variant)]
 pub enum OrchestratorResponse {
     /// Compilation succeeded — a runbook is ready for execution.
     Compiled(CompiledRunbookSummary),
@@ -131,7 +132,7 @@ pub struct ClarificationContext {
     pub is_macro: bool,
 
     /// Arguments that were successfully extracted.
-    pub extracted_args: std::collections::HashMap<String, String>,
+    pub extracted_args: std::collections::BTreeMap<String, String>,
 }
 
 // ---------------------------------------------------------------------------
@@ -225,6 +226,25 @@ mod tests {
         assert!(back.is_compiled());
     }
 
+    #[test]
+    fn compilation_error_response_serde_round_trip() {
+        use super::super::errors::{CompilationError, CompilationErrorKind};
+
+        let resp = OrchestratorResponse::CompilationError(CompilationError::new(
+            CompilationErrorKind::PackConstraint {
+                verb: "cbu.delete".into(),
+                explanation: "forbidden by kyc-case pack".into(),
+            },
+            "pack_gate",
+        ));
+        let json = serde_json::to_string(&resp).unwrap();
+        assert!(json.contains("compilation_error"));
+        assert!(json.contains("pack_gate"));
+        let back: OrchestratorResponse = serde_json::from_str(&json).unwrap();
+        assert!(!back.is_compiled());
+        assert!(matches!(back, OrchestratorResponse::CompilationError(_)));
+    }
+
     #[test]
     fn constraint_violation_serde() {
         let violation = OrchestratorResponse::ConstraintViolation(ConstraintViolationDetail {
diff --git a/rust/src/runbook/write_set.rs b/rust/src/runbook/write_set.rs
index 6f6cc0a..68bc69f 100644
--- a/rust/src/runbook/write_set.rs
+++ b/rust/src/runbook/write_set.rs
@@ -14,7 +14,7 @@
 //! strategies (contract ∪ heuristic, deduplicated) when the feature is
 //! enabled, or just the heuristic when it is not.
 
-use std::collections::{BTreeSet, HashMap};
+use std::collections::{BTreeMap, BTreeSet};
 use uuid::Uuid;
 
 #[cfg(feature = "write-set-contract")]
@@ -30,7 +30,7 @@ use crate::repl::verb_config_index::VerbConfigIndex;
 /// argument values (e.g., `:entity-id <uuid>`, `:cbu-id <uuid>`).
 ///
 /// Returns a `BTreeSet` for deterministic ordering (INV-2).
-pub fn derive_write_set_heuristic(args: &HashMap<String, String>) -> BTreeSet<Uuid> {
+pub fn derive_write_set_heuristic(args: &BTreeMap<String, String>) -> BTreeSet<Uuid> {
     args.values()
         .filter_map(|v| {
             let trimmed = v.trim().trim_matches(|c| c == '<' || c == '>');
@@ -55,7 +55,7 @@ pub fn derive_write_set_heuristic(args: &HashMap<String, String>) -> BTreeSet<Uu
 #[cfg(feature = "write-set-contract")]
 pub fn derive_write_set_from_contract(
     verb_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     verb_config_index: &VerbConfigIndex,
 ) -> BTreeSet<Uuid> {
     let mut write_set = BTreeSet::new();
@@ -121,7 +121,7 @@ pub fn derive_write_set_from_contract(
 #[cfg(feature = "write-set-contract")]
 pub fn derive_write_set(
     verb_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     verb_config_index: Option<&VerbConfigIndex>,
 ) -> BTreeSet<Uuid> {
     let mut result = derive_write_set_heuristic(args);
@@ -138,7 +138,7 @@ pub fn derive_write_set(
 #[cfg(not(feature = "write-set-contract"))]
 pub fn derive_write_set(
     _verb_fqn: &str,
-    args: &HashMap<String, String>,
+    args: &BTreeMap<String, String>,
     _verb_config_index: Option<&()>,
 ) -> BTreeSet<Uuid> {
     derive_write_set_heuristic(args)
@@ -156,7 +156,7 @@ mod tests {
     fn test_heuristic_extracts_uuids_from_args() {
         let id1 = Uuid::new_v4();
         let id2 = Uuid::new_v4();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("entity-id".to_string(), id1.to_string());
         args.insert("cbu-id".to_string(), format!("<{}>", id2));
         args.insert("name".to_string(), "Acme Corp".to_string());
@@ -169,7 +169,7 @@ mod tests {
 
     #[test]
     fn test_heuristic_ignores_non_uuids() {
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("name".to_string(), "Acme Corp".to_string());
         args.insert("jurisdiction".to_string(), "LU".to_string());
         args.insert("count".to_string(), "42".to_string());
@@ -181,7 +181,7 @@ mod tests {
     #[test]
     fn test_heuristic_fallback_when_no_contract() {
         let id = Uuid::new_v4();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("entity-id".to_string(), id.to_string());
 
         // With no verb_config_index, derive_write_set falls back to heuristic
@@ -202,7 +202,7 @@ mod tests {
         // INV-2: output must be BTreeSet, not HashSet
         let id1 = Uuid::new_v4();
         let id2 = Uuid::new_v4();
-        let mut args = HashMap::new();
+        let mut args = BTreeMap::new();
         args.insert("a".to_string(), id1.to_string());
         args.insert("b".to_string(), id2.to_string());
 
@@ -287,7 +287,7 @@ mod tests {
         fn test_contract_extracts_crud_key_arg() {
             let index = test_index();
             let cbu_id = Uuid::new_v4();
-            let mut args = HashMap::new();
+            let mut args = BTreeMap::new();
             args.insert("cbu-id".to_string(), cbu_id.to_string());
             args.insert("name".to_string(), "New Name".to_string());
 
@@ -303,7 +303,7 @@ mod tests {
         fn test_contract_extracts_entity_lookup_arg() {
             let index = test_index();
             let parent_id = Uuid::new_v4();
-            let mut args = HashMap::new();
+            let mut args = BTreeMap::new();
             args.insert("name".to_string(), "Child Corp".to_string());
             args.insert("parent-entity-id".to_string(), parent_id.to_string());
 
@@ -319,7 +319,7 @@ mod tests {
             let index = test_index();
             let cbu_id = Uuid::new_v4();
             let extra_id = Uuid::new_v4();
-            let mut args = HashMap::new();
+            let mut args = BTreeMap::new();
             args.insert("cbu-id".to_string(), cbu_id.to_string());
             // An arg not in the contract but contains a UUID — heuristic picks it up
             args.insert("extra-ref".to_string(), extra_id.to_string());
@@ -333,7 +333,7 @@ mod tests {
         #[test]
         fn test_contract_unknown_verb_returns_empty() {
             let index = test_index();
-            let mut args = HashMap::new();
+            let mut args = BTreeMap::new();
             args.insert("id".to_string(), Uuid::new_v4().to_string());
 
             let result = derive_write_set_from_contract("nonexistent.verb", &args, &index);
diff --git a/rust/tests/runbook_e2e_test.rs b/rust/tests/runbook_e2e_test.rs
index 84ab6bb..e047880 100644
--- a/rust/tests/runbook_e2e_test.rs
+++ b/rust/tests/runbook_e2e_test.rs
@@ -228,7 +228,7 @@ async fn test_primitive_verb_round_trip() {
         fqn: "cbu.create".to_string(),
     };
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "E2E Fund".to_string());
 
     let resp = compile_verb(
@@ -316,7 +316,7 @@ async fn test_macro_expands_to_primitives() {
     );
 
     let session = test_session();
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Macro Test Fund".to_string());
 
     // Expand via fixpoint
@@ -450,7 +450,7 @@ async fn test_nested_macro_fixpoint() {
     );
 
     let session = test_session();
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Nested Fund".to_string());
     args.insert("party-name".to_string(), "GP Entity".to_string());
 
@@ -550,7 +550,7 @@ fn test_cycle_detection() {
     );
 
     let session = test_session();
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("x".to_string(), "test".to_string());
 
     let result = expand_macro_fixpoint("cycle.a", &args, &session, &registry, Default::default());
@@ -617,7 +617,7 @@ fn test_depth_limit() {
     }
 
     let session = test_session();
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("x".to_string(), "test".to_string());
 
     let limits = ExpansionLimits {
@@ -686,7 +686,7 @@ fn test_pack_constraint_blocks_forbidden_verb() {
         }],
     };
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Blocked Fund".to_string());
 
     let resp = compile_invocation(
@@ -922,7 +922,7 @@ async fn test_write_set_locks_acquired() {
     );
 
     // INV-8: Verify heuristic write_set derivation works
-    let mut heuristic_args = HashMap::new();
+    let mut heuristic_args = BTreeMap::new();
     heuristic_args.insert("entity-id".to_string(), entity_id_1.to_string());
     heuristic_args.insert("name".to_string(), "Acme Corp".to_string());
     let heuristic_ws = ob_poc::runbook::write_set::derive_write_set_heuristic(&heuristic_args);
diff --git a/rust/tests/runbook_pipeline_test.rs b/rust/tests/runbook_pipeline_test.rs
index e1ac9d4..45cd19b 100644
--- a/rust/tests/runbook_pipeline_test.rs
+++ b/rust/tests/runbook_pipeline_test.rs
@@ -19,7 +19,7 @@
 
 #![cfg(feature = "vnext-repl")]
 
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeMap, HashMap, HashSet};
 use uuid::Uuid;
 
 use ob_poc::dsl_v2::macros::{
@@ -303,7 +303,7 @@ fn make_step(verb: &str) -> CompiledStep {
 /// Helper: compile + execute a macro through the full pipeline.
 async fn compile_and_execute(
     macro_name: &str,
-    args: HashMap<String, String>,
+    args: BTreeMap<String, String>,
     registry: &MacroRegistry,
     constraints: &EffectiveConstraints,
 ) -> (
@@ -354,7 +354,7 @@ async fn macro_end_to_end() {
     let registry = macro_registry_with_structure_setup();
     let constraints = EffectiveConstraints::unconstrained();
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Acme Fund".to_string());
 
     let (resp, exec_result) =
@@ -407,7 +407,7 @@ async fn pack_scoping() {
         }],
     };
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Acme Fund".to_string());
 
     let (resp, exec_result) =
@@ -489,7 +489,7 @@ async fn pack_completion_widening() {
 
     // Now cbu.create should compile successfully
     let registry = macro_registry_with_structure_setup();
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Widened Fund".to_string());
 
     let (resp, exec_result) =
@@ -521,7 +521,7 @@ async fn replay_determinism() {
     let verb_index = VerbConfigIndex::empty();
     let constraints = EffectiveConstraints::unconstrained();
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Determinism Test".to_string());
 
     let classification = classify_verb("structure.full-setup", &verb_index, &registry);
@@ -760,7 +760,7 @@ async fn constraint_violation_remediation() {
     let verb_index = VerbConfigIndex::empty();
     let classification = classify_verb("structure.setup", &verb_index, &registry);
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Blocked Fund".to_string());
 
     let resp = compile_verb(
@@ -880,7 +880,7 @@ async fn multi_step_macro_pipeline() {
     let registry = macro_registry_with_multi_step();
     let constraints = EffectiveConstraints::unconstrained();
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Multi-Step Fund".to_string());
 
     let (resp, exec_result) =
@@ -972,7 +972,7 @@ async fn primitive_verb_compile_and_execute() {
         fqn: "cbu.create".to_string(),
     };
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Direct Fund".to_string());
 
     let resp = compile_verb(
@@ -1025,7 +1025,7 @@ fn compile_invocation_missing_macro_args() {
     let constraints = EffectiveConstraints::unconstrained();
 
     // Call compile_invocation with NO args — "name" is required by the macro
-    let args = HashMap::new();
+    let args = BTreeMap::new();
 
     let resp = ob_poc::runbook::compile_invocation(
         Uuid::new_v4(),
@@ -1077,7 +1077,7 @@ fn compile_invocation_end_to_end() {
     let session = test_session();
     let constraints = EffectiveConstraints::unconstrained();
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "E2E Fund".to_string());
 
     let resp = ob_poc::runbook::compile_invocation(
@@ -1132,7 +1132,7 @@ fn compile_invocation_constraint_violation() {
         }],
     };
 
-    let mut args = HashMap::new();
+    let mut args = BTreeMap::new();
     args.insert("name".to_string(), "Blocked Fund".to_string());
 
     let resp = ob_poc::runbook::compile_invocation(
