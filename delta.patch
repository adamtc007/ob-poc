diff --git a/CLAUDE.md b/CLAUDE.md
index bb115c65..4e98af2b 100644
--- a/CLAUDE.md
+++ b/CLAUDE.md
@@ -144,14 +144,13 @@ User says: "spin up a fund for Acme"
             verb_search tool
                     ↓
     ┌───────────────┴───────────────┐
-    │     Search Priority (7-tier)   │
+    │     Search Priority (6-tier)   │
     │  1. User learned (exact)       │
     │  2. Global learned (exact)     │
     │  3. User semantic (pgvector)   │
     │  4. Global semantic (pgvector) │
     │  5. Blocklist check            │
-    │  6. YAML invocation_phrases    │
-    │  7. Cold start semantic        │
+    │  6. Global semantic fallback   │
     └───────────────┬───────────────┘
                     ↓
             Top match: cbu.create
@@ -279,8 +278,9 @@ User says: "spin up a fund for Acme"
 
 On server startup (`ob-poc-web/src/main.rs`):
 1. Load verb YAML config
-2. `VerbSyncService.sync_all_with_phrases()` syncs verbs AND invocation_phrases to `dsl_verbs.intent_patterns`
+2. `VerbSyncService.sync_all_with_phrases()` syncs verbs AND invocation_phrases to `dsl_verbs.yaml_intent_patterns`
 3. `populate_embeddings` must be run separately to create vectors
+4. Background learning task spawns (30s delay, then 6hr interval)
 
 **Populating Embeddings:**
 
@@ -301,20 +301,26 @@ All DB access goes through `VerbService` (no direct sqlx calls).
 1. User learned exact → `agent.user_learned_phrases`
 2. Global learned exact → In-memory LearnedData
 3. User semantic → pgvector on user_learned_phrases
-4. Global semantic → pgvector on invocation_phrases
+4. Global semantic → pgvector on `verb_pattern_embeddings`
 5. Blocklist check → Filter blocked verbs
-6. **Global semantic → `verb_pattern_embeddings`** ← PRIMARY LOOKUP
+6. **Global semantic fallback** ← Lower threshold, wider net
 
-> **Removed (2026-01-19):** Tier 6 YAML phrase matching via `VerbPhraseIndex` has been removed.
-> All verb discovery now goes through DB-sourced semantic search.
+**Pattern Sources (v_verb_intent_patterns view):**
+- `yaml_intent_patterns` - YAML invocation_phrases, overwritten on startup
+- `intent_patterns` - Learned patterns, preserved across restarts
 
 **Learning Loop:**
 
-When users correct the system:
-1. `PatternLearner.add_pattern()` calls `add_learned_pattern(verb, phrase)`
-2. Pattern added to `dsl_verbs.intent_patterns`
-3. Re-run `populate_embeddings` to create vector
-4. Future queries now match the learned phrase
+Automatic learning via background task (or MCP tools):
+1. `learning_analyze` identifies high-frequency unmatched phrases
+2. `learning_apply` promotes candidates to `dsl_verbs.intent_patterns`
+3. `populate_embeddings` creates vectors for new patterns
+4. Future queries match the learned phrases
+
+**MCP Tools:**
+- `learning_analyze` - Find patterns worth learning (days_back, min_occurrences)
+- `learning_apply` - Apply a specific pattern → verb mapping
+- `embeddings_status` - Check embedding coverage stats
 
 **Coverage Stats:**
 
@@ -322,6 +328,8 @@ When users correct the system:
 SELECT * FROM "ob-poc".v_verb_embedding_stats;
 -- total_verbs: 923
 -- verbs_with_patterns: 923
+-- verbs_with_yaml_patterns: 920   -- From YAML invocation_phrases
+-- verbs_with_learned_patterns: 15 -- From learning loop
 -- total_embeddings: 7500+
 -- unique_verbs_embedded: 962
 ```
diff --git a/migrations/038_split_yaml_learned_patterns.sql b/migrations/038_split_yaml_learned_patterns.sql
new file mode 100644
index 00000000..5726b1e3
--- /dev/null
+++ b/migrations/038_split_yaml_learned_patterns.sql
@@ -0,0 +1,98 @@
+-- Migration 038: Split YAML and learned intent patterns
+--
+-- PROBLEM: sync_invocation_phrases overwrites intent_patterns on startup,
+--          which deletes learned patterns added by the learning loop.
+--
+-- SOLUTION: Add yaml_intent_patterns column for YAML-sourced patterns.
+--           Learning loop continues to use intent_patterns (which becomes learned-only).
+--           View v_verb_intent_patterns unions both for embedding.
+--
+-- FLOW:
+--   YAML invocation_phrases → dsl_verbs.yaml_intent_patterns (startup sync)
+--   Learning loop → dsl_verbs.intent_patterns (learned patterns)
+--   v_verb_intent_patterns → UNION of both → populate_embeddings
+
+-- 1. Add yaml_intent_patterns column
+ALTER TABLE "ob-poc".dsl_verbs
+ADD COLUMN IF NOT EXISTS yaml_intent_patterns text[] DEFAULT ARRAY[]::text[];
+
+COMMENT ON COLUMN "ob-poc".dsl_verbs.yaml_intent_patterns IS
+    'Intent patterns from YAML invocation_phrases - synced on startup, safe to overwrite';
+
+COMMENT ON COLUMN "ob-poc".dsl_verbs.intent_patterns IS
+    'Learned intent patterns from feedback loop - NOT overwritten on startup';
+
+-- 2. Migrate existing intent_patterns to yaml_intent_patterns (one-time)
+-- This preserves current patterns as the YAML baseline
+UPDATE "ob-poc".dsl_verbs
+SET yaml_intent_patterns = COALESCE(intent_patterns, ARRAY[]::text[])
+WHERE yaml_intent_patterns IS NULL OR yaml_intent_patterns = ARRAY[]::text[];
+
+-- 3. Dedupe: remove from intent_patterns anything that's now in yaml_intent_patterns
+-- This preserves only "true learned deltas" in intent_patterns
+UPDATE "ob-poc".dsl_verbs
+SET intent_patterns = (
+  SELECT COALESCE(array_agg(DISTINCT p), ARRAY[]::text[])
+  FROM unnest(COALESCE(intent_patterns, ARRAY[]::text[])) p
+  WHERE NOT (p = ANY(COALESCE(yaml_intent_patterns, ARRAY[]::text[])))
+)
+WHERE intent_patterns IS NOT NULL
+  AND array_length(intent_patterns, 1) > 0;
+
+-- 4. Update the view to UNION both pattern sources
+CREATE OR REPLACE VIEW "ob-poc".v_verb_intent_patterns AS
+SELECT
+    v.full_name as verb_full_name,
+    pattern,
+    COALESCE(m.category, 'general') as category,
+    m.is_agent_bound,
+    COALESCE(m.priority, 1) as priority,
+    'yaml' as source
+FROM "ob-poc".dsl_verbs v
+CROSS JOIN LATERAL unnest(v.yaml_intent_patterns) as pattern
+LEFT JOIN "ob-poc".verb_metadata m ON m.verb_full_name = v.full_name
+WHERE v.yaml_intent_patterns IS NOT NULL
+  AND array_length(v.yaml_intent_patterns, 1) > 0
+
+UNION ALL
+
+SELECT
+    v.full_name as verb_full_name,
+    pattern,
+    COALESCE(m.category, 'general') as category,
+    m.is_agent_bound,
+    COALESCE(m.priority, 2) as priority,  -- Learned patterns get higher priority
+    'learned' as source
+FROM "ob-poc".dsl_verbs v
+CROSS JOIN LATERAL unnest(v.intent_patterns) as pattern
+LEFT JOIN "ob-poc".verb_metadata m ON m.verb_full_name = v.full_name
+WHERE v.intent_patterns IS NOT NULL
+  AND array_length(v.intent_patterns, 1) > 0;
+
+COMMENT ON VIEW "ob-poc".v_verb_intent_patterns IS
+    'Flattened view of all intent patterns (YAML + learned) for embedding population';
+
+-- 5. Update stats view to show both sources
+CREATE OR REPLACE VIEW "ob-poc".v_verb_embedding_stats AS
+SELECT
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs) as total_verbs,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE (yaml_intent_patterns IS NOT NULL AND array_length(yaml_intent_patterns, 1) > 0)
+        OR (intent_patterns IS NOT NULL AND array_length(intent_patterns, 1) > 0)) as verbs_with_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE yaml_intent_patterns IS NOT NULL AND array_length(yaml_intent_patterns, 1) > 0) as verbs_with_yaml_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE intent_patterns IS NOT NULL AND array_length(intent_patterns, 1) > 0) as verbs_with_learned_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".verb_pattern_embeddings WHERE embedding IS NOT NULL) as total_embeddings,
+    (SELECT COUNT(DISTINCT verb_name) FROM "ob-poc".verb_pattern_embeddings) as unique_verbs_embedded;
+
+COMMENT ON VIEW "ob-poc".v_verb_embedding_stats IS
+    'Statistics for verb embedding coverage - split by YAML vs learned patterns';
+
+-- 6. Update add_learned_pattern to ensure it goes to intent_patterns (not yaml)
+-- (Already correct - appends to intent_patterns)
+
+-- 7. Add index for yaml_intent_patterns lookups
+CREATE INDEX IF NOT EXISTS idx_dsl_verbs_yaml_patterns
+ON "ob-poc".dsl_verbs USING GIN (yaml_intent_patterns)
+WHERE yaml_intent_patterns IS NOT NULL;
diff --git a/rust/crates/ob-poc-web/src/main.rs b/rust/crates/ob-poc-web/src/main.rs
index d1a8d1a1..7636146a 100644
--- a/rust/crates/ob-poc-web/src/main.rs
+++ b/rust/crates/ob-poc-web/src/main.rs
@@ -40,6 +40,10 @@ use ob_poc::dsl_v2::{gateway_resolver::gateway_addr, GatewayRefResolver};
 use ob_poc::dsl_v2::ConfigLoader;
 use ob_poc::session::VerbSyncService;
 
+// Import background learning task
+use ob_poc::agent::learning::{create_learning_status, spawn_learning_task, LearningConfig};
+use std::sync::atomic::AtomicBool;
+
 // EntityGateway for entity resolution
 use entity_gateway::{
     config::StartupMode,
@@ -456,6 +460,22 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
         }
     };
 
+    // =========================================================================
+    // Spawn background learning task (non-blocking)
+    // =========================================================================
+    let learning_config = LearningConfig::from_env();
+    let learning_status = create_learning_status();
+    let shutdown_flag = Arc::new(AtomicBool::new(false));
+
+    spawn_learning_task(
+        pool.clone(),
+        learning_config,
+        learning_status,
+        shutdown_flag,
+    );
+
+    tracing::info!("Background learning task spawned");
+
     if let Err(e) = axum::serve(listener, app).await {
         tracing::error!("Server error: {}", e);
         return Err(format!("Server error: {}", e).into());
diff --git a/rust/src/agent/learning/background.rs b/rust/src/agent/learning/background.rs
new file mode 100644
index 00000000..67b2d4ea
--- /dev/null
+++ b/rust/src/agent/learning/background.rs
@@ -0,0 +1,290 @@
+//! Background learning task
+//!
+//! Spawns after server startup to periodically:
+//! 1. Run feedback analysis
+//! 2. Auto-apply high-confidence patterns
+//! 3. Check embedding coverage (warn if stale)
+//!
+//! Does NOT block startup - runs in background tokio task.
+
+use anyhow::Result;
+use ob_semantic_matcher::{FeedbackService, PatternLearner};
+use sqlx::PgPool;
+use std::sync::atomic::{AtomicBool, Ordering};
+use std::sync::Arc;
+use std::time::Duration;
+use tokio::sync::RwLock;
+use tracing::{error, info, warn};
+
+/// Status of the learning system
+#[derive(Debug, Clone, Default)]
+pub struct LearningStatus {
+    /// Last time analysis was run
+    pub last_analysis: Option<chrono::DateTime<chrono::Utc>>,
+    /// Patterns applied in last run
+    pub last_patterns_applied: usize,
+    /// Pending embeddings count (patterns without vectors)
+    pub pending_embeddings: i64,
+    /// Whether embeddings are considered stale
+    pub embeddings_stale: bool,
+    /// Error from last run (if any)
+    pub last_error: Option<String>,
+}
+
+/// Shared learning status accessible from MCP tools
+pub type SharedLearningStatus = Arc<RwLock<LearningStatus>>;
+
+/// Create shared learning status
+pub fn create_learning_status() -> SharedLearningStatus {
+    Arc::new(RwLock::new(LearningStatus::default()))
+}
+
+/// Configuration for the background learning task
+#[derive(Debug, Clone)]
+pub struct LearningConfig {
+    /// Delay before first run (let server stabilize)
+    pub initial_delay_secs: u64,
+    /// Interval between learning runs
+    pub interval_secs: u64,
+    /// Days of feedback to analyze
+    pub analysis_days_back: i32,
+    /// Minimum occurrences to auto-apply a pattern
+    pub min_occurrences: i64,
+    /// Whether to run learning on startup (after delay)
+    pub run_on_startup: bool,
+}
+
+impl Default for LearningConfig {
+    fn default() -> Self {
+        Self {
+            initial_delay_secs: 30,     // Wait 30s after startup
+            interval_secs: 6 * 60 * 60, // Every 6 hours
+            analysis_days_back: 7,      // Look at last 7 days
+            min_occurrences: 5,         // Need 5+ occurrences to auto-apply
+            run_on_startup: true,       // Check embeddings on startup
+        }
+    }
+}
+
+impl LearningConfig {
+    /// Load from environment variables
+    pub fn from_env() -> Self {
+        Self {
+            initial_delay_secs: std::env::var("LEARNING_INITIAL_DELAY")
+                .ok()
+                .and_then(|s| s.parse().ok())
+                .unwrap_or(30),
+            interval_secs: std::env::var("LEARNING_INTERVAL_SECS")
+                .ok()
+                .and_then(|s| s.parse().ok())
+                .unwrap_or(6 * 60 * 60),
+            analysis_days_back: std::env::var("LEARNING_DAYS_BACK")
+                .ok()
+                .and_then(|s| s.parse().ok())
+                .unwrap_or(7),
+            min_occurrences: std::env::var("LEARNING_MIN_OCCURRENCES")
+                .ok()
+                .and_then(|s| s.parse().ok())
+                .unwrap_or(5),
+            run_on_startup: std::env::var("LEARNING_ON_STARTUP")
+                .map(|s| s != "false" && s != "0")
+                .unwrap_or(true),
+        }
+    }
+}
+
+/// Spawn background learning task
+///
+/// Returns immediately - task runs in background.
+/// Use shutdown flag to gracefully stop the task.
+pub fn spawn_learning_task(
+    pool: PgPool,
+    config: LearningConfig,
+    status: SharedLearningStatus,
+    shutdown: Arc<AtomicBool>,
+) {
+    tokio::spawn(async move {
+        info!(
+            "Learning task starting in {}s (interval: {}s)",
+            config.initial_delay_secs, config.interval_secs
+        );
+
+        // Initial delay to let server stabilize
+        tokio::time::sleep(Duration::from_secs(config.initial_delay_secs)).await;
+
+        if shutdown.load(Ordering::Relaxed) {
+            info!("Learning task shutdown before first run");
+            return;
+        }
+
+        let feedback_service = FeedbackService::new(pool.clone());
+        let pattern_learner = PatternLearner::new(pool.clone());
+
+        // Initial check on startup
+        if config.run_on_startup {
+            if let Err(e) = check_embedding_coverage(&pattern_learner, &status).await {
+                warn!("Initial embedding check failed: {}", e);
+            }
+        }
+
+        loop {
+            if shutdown.load(Ordering::Relaxed) {
+                info!("Learning task shutting down");
+                break;
+            }
+
+            // Run learning cycle
+            match run_learning_cycle(&feedback_service, &pattern_learner, &config, &status).await {
+                Ok(applied) => {
+                    if applied > 0 {
+                        info!("Learning cycle complete: {} patterns applied", applied);
+                    }
+                }
+                Err(e) => {
+                    error!("Learning cycle failed: {}", e);
+                    let mut s = status.write().await;
+                    s.last_error = Some(e.to_string());
+                }
+            }
+
+            // Sleep until next interval
+            tokio::select! {
+                _ = tokio::time::sleep(Duration::from_secs(config.interval_secs)) => {}
+                _ = async {
+                    while !shutdown.load(Ordering::Relaxed) {
+                        tokio::time::sleep(Duration::from_millis(100)).await;
+                    }
+                } => {
+                    info!("Learning task interrupted by shutdown");
+                    break;
+                }
+            }
+        }
+    });
+}
+
+/// Run a single learning cycle
+pub async fn run_learning_cycle(
+    feedback_service: &FeedbackService,
+    pattern_learner: &PatternLearner,
+    config: &LearningConfig,
+    status: &SharedLearningStatus,
+) -> Result<usize> {
+    info!(
+        "Running learning cycle (analyzing {} days of feedback)",
+        config.analysis_days_back
+    );
+
+    // 1. Run feedback analysis
+    let report = feedback_service.analyze(config.analysis_days_back).await?;
+
+    if report.is_empty() {
+        info!("No patterns to learn from feedback");
+        let mut s = status.write().await;
+        s.last_analysis = Some(chrono::Utc::now());
+        s.last_patterns_applied = 0;
+        s.last_error = None;
+        return Ok(0);
+    }
+
+    info!(
+        "Analysis found: {} pattern discoveries, {} confusion pairs, {} gaps",
+        report.pattern_discoveries.len(),
+        report.confusion_pairs.len(),
+        report.gaps.len()
+    );
+
+    // 2. Auto-apply high-confidence patterns
+    let applied = pattern_learner
+        .auto_apply_discoveries(&report.pattern_discoveries, config.min_occurrences)
+        .await?;
+
+    // 3. Check embedding coverage
+    let pending = pattern_learner.count_pending_embeddings().await?;
+
+    // 4. Update status
+    {
+        let mut s = status.write().await;
+        s.last_analysis = Some(chrono::Utc::now());
+        s.last_patterns_applied = applied.len();
+        s.pending_embeddings = pending;
+        s.embeddings_stale = pending > 0;
+        s.last_error = None;
+    }
+
+    if pending > 0 {
+        warn!(
+            "{} patterns pending embeddings. Run: cargo run --bin populate_embeddings",
+            pending
+        );
+    }
+
+    Ok(applied.len())
+}
+
+/// Check embedding coverage and update status
+async fn check_embedding_coverage(
+    pattern_learner: &PatternLearner,
+    status: &SharedLearningStatus,
+) -> Result<()> {
+    let pending = pattern_learner.count_pending_embeddings().await?;
+
+    {
+        let mut s = status.write().await;
+        s.pending_embeddings = pending;
+        s.embeddings_stale = pending > 0;
+    }
+
+    if pending > 0 {
+        warn!(
+            "Embedding coverage check: {} patterns missing vectors",
+            pending
+        );
+        warn!("Run: cargo run --release --bin populate_embeddings");
+    } else {
+        info!("Embedding coverage OK: all patterns have vectors");
+    }
+
+    Ok(())
+}
+
+/// Manually trigger a learning cycle (for MCP tool)
+pub async fn trigger_learning_cycle(
+    pool: &PgPool,
+    days_back: i32,
+    min_occurrences: i64,
+) -> Result<LearningCycleResult> {
+    let feedback_service = FeedbackService::new(pool.clone());
+    let pattern_learner = PatternLearner::new(pool.clone());
+
+    // Run analysis
+    let report = feedback_service.analyze(days_back).await?;
+
+    // Apply patterns
+    let applied = pattern_learner
+        .auto_apply_discoveries(&report.pattern_discoveries, min_occurrences)
+        .await?;
+
+    // Check pending
+    let pending_embeddings = pattern_learner.count_pending_embeddings().await?;
+
+    Ok(LearningCycleResult {
+        patterns_discovered: report.pattern_discoveries.len(),
+        confusion_pairs: report.confusion_pairs.len(),
+        gaps: report.gaps.len(),
+        patterns_applied: applied.len(),
+        applied_patterns: applied,
+        pending_embeddings,
+    })
+}
+
+/// Result of a learning cycle
+#[derive(Debug, Clone, serde::Serialize)]
+pub struct LearningCycleResult {
+    pub patterns_discovered: usize,
+    pub confusion_pairs: usize,
+    pub gaps: usize,
+    pub patterns_applied: usize,
+    pub applied_patterns: Vec<(String, String)>,
+    pub pending_embeddings: i64,
+}
diff --git a/rust/src/agent/learning/mod.rs b/rust/src/agent/learning/mod.rs
index b59686a9..d2c1deff 100644
--- a/rust/src/agent/learning/mod.rs
+++ b/rust/src/agent/learning/mod.rs
@@ -32,6 +32,7 @@
 //! Both loops use fire-and-forget emission (< 1μs overhead) with background
 //! database persistence.
 
+pub mod background;
 pub mod decay;
 pub mod drain;
 pub mod embedder;
@@ -53,3 +54,8 @@ pub use types::{
     ResolutionMethod, ResolvedEntity,
 };
 pub use warmup::{LearnedData, LearningWarmup, SharedLearnedData, WarmupStats};
+
+pub use background::{
+    create_learning_status, spawn_learning_task, trigger_learning_cycle, LearningConfig,
+    LearningCycleResult, LearningStatus as BackgroundLearningStatus, SharedLearningStatus,
+};
diff --git a/rust/src/mcp/handlers/core.rs b/rust/src/mcp/handlers/core.rs
index f5aa688b..53225f18 100644
--- a/rust/src/mcp/handlers/core.rs
+++ b/rust/src/mcp/handlers/core.rs
@@ -387,6 +387,10 @@ impl ToolHandlers {
             "esper_lookup" => self.esper_lookup(args).await,
             "esper_add_alias" => self.esper_add_alias(args).await,
             "esper_reload" => self.esper_reload(args).await,
+            // Learning system tools
+            "learning_analyze" => self.learning_analyze(args).await,
+            "learning_apply" => self.learning_apply(args).await,
+            "embeddings_status" => self.embeddings_status(args).await,
             _ => Err(anyhow!("Unknown tool: {}", name)),
         }
     }
@@ -5963,6 +5967,111 @@ impl ToolHandlers {
             }
         }))
     }
+
+    // =========================================================================
+    // Learning System Tools
+    // =========================================================================
+
+    /// Analyze user feedback to discover learnable patterns
+    async fn learning_analyze(&self, args: Value) -> Result<Value> {
+        use ob_semantic_matcher::FeedbackService;
+
+        let days_back = args.get("days_back").and_then(|v| v.as_i64()).unwrap_or(7) as i32;
+
+        let feedback_service = FeedbackService::new(self.pool.clone());
+        let report = feedback_service.analyze(days_back).await?;
+
+        Ok(json!({
+            "success": true,
+            "days_analyzed": days_back,
+            "summary": report.summary(),
+            "pattern_discoveries": report.pattern_discoveries.len(),
+            "confusion_pairs": report.confusion_pairs.len(),
+            "gaps": report.gaps.len(),
+            "low_score_successes": report.low_score_successes.len(),
+            "details": {
+                "patterns": report.pattern_discoveries.iter().take(10).collect::<Vec<_>>(),
+                "confusions": report.confusion_pairs.iter().take(5).collect::<Vec<_>>(),
+                "gaps": report.gaps.iter().take(5).collect::<Vec<_>>()
+            }
+        }))
+    }
+
+    /// Apply discovered patterns to improve verb matching
+    async fn learning_apply(&self, args: Value) -> Result<Value> {
+        use crate::agent::learning::trigger_learning_cycle;
+
+        let days_back = args.get("days_back").and_then(|v| v.as_i64()).unwrap_or(7) as i32;
+
+        let min_occurrences = args
+            .get("min_occurrences")
+            .and_then(|v| v.as_i64())
+            .unwrap_or(5);
+
+        let result = trigger_learning_cycle(&self.pool, days_back, min_occurrences).await?;
+
+        let needs_reembed = result.pending_embeddings > 0;
+
+        Ok(json!({
+            "success": true,
+            "days_analyzed": days_back,
+            "min_occurrences": min_occurrences,
+            "patterns_discovered": result.patterns_discovered,
+            "patterns_applied": result.patterns_applied,
+            "applied_patterns": result.applied_patterns,
+            "pending_embeddings": result.pending_embeddings,
+            "needs_reembed": needs_reembed,
+            "message": if needs_reembed {
+                format!("{} patterns applied. {} patterns need embedding. Run: cargo run --release --bin populate_embeddings",
+                    result.patterns_applied, result.pending_embeddings)
+            } else if result.patterns_applied > 0 {
+                format!("{} patterns applied and ready for use", result.patterns_applied)
+            } else {
+                "No new patterns to apply".to_string()
+            }
+        }))
+    }
+
+    /// Check embedding coverage for verb patterns
+    async fn embeddings_status(&self, _args: Value) -> Result<Value> {
+        use ob_semantic_matcher::PatternLearner;
+
+        let learner = PatternLearner::new(self.pool.clone());
+        let pending = learner.count_pending_embeddings().await?;
+
+        // Get total counts
+        let total_patterns: (i64,) =
+            sqlx::query_as(r#"SELECT COUNT(*) FROM "ob-poc".v_verb_intent_patterns"#)
+                .fetch_one(&self.pool)
+                .await?;
+
+        let total_embeddings: (i64,) = sqlx::query_as(
+            r#"SELECT COUNT(*) FROM "ob-poc".verb_pattern_embeddings WHERE embedding IS NOT NULL"#,
+        )
+        .fetch_one(&self.pool)
+        .await?;
+
+        let coverage = if total_patterns.0 > 0 {
+            (total_embeddings.0 as f64 / total_patterns.0 as f64 * 100.0).round()
+        } else {
+            0.0
+        };
+
+        Ok(json!({
+            "success": true,
+            "total_patterns": total_patterns.0,
+            "embedded_patterns": total_embeddings.0,
+            "pending_patterns": pending,
+            "coverage_percent": coverage,
+            "needs_reembed": pending > 0,
+            "message": if pending > 0 {
+                format!("{} patterns need embedding ({}% coverage). Run: cargo run --release --bin populate_embeddings",
+                    pending, coverage)
+            } else {
+                format!("All patterns embedded ({}% coverage)", coverage)
+            }
+        }))
+    }
 }
 
 // Helper struct for attribute gap query
diff --git a/rust/src/mcp/tools.rs b/rust/src/mcp/tools.rs
index b22a0353..ee59f0ae 100644
--- a/rust/src/mcp/tools.rs
+++ b/rust/src/mcp/tools.rs
@@ -229,18 +229,21 @@ pub fn get_tools() -> Vec<Tool> {
             description: r#"Search for DSL verbs matching natural language intent.
 
 Uses a hybrid search strategy in priority order:
-1. LEARNED phrases (from user corrections) - exact match, highest confidence
-2. YAML invocation_phrases - exact and substring matches
-3. Semantic embeddings (pgvector) - fallback for novel phrases
+1. User learned exact - phrases user taught us (highest confidence)
+2. Global learned exact - phrases learned from all users
+3. User learned semantic - pgvector similarity on user phrases
+4. Global learned semantic - pgvector on global learned phrases
+5. Blocklist check - filters blocked verb mappings
+6. Global semantic (PRIMARY) - pgvector on verb_pattern_embeddings
 
 Returns ranked candidates with source attribution:
-- learned: User taught us this phrase→verb mapping
-- phrase_exact: Exact match from YAML invocation_phrases
-- phrase_substring: Partial match from YAML
-- semantic: Embedding similarity (fallback)
+- user_learned_exact: User-specific learned mapping
+- learned_exact: Global learned mapping
+- user_learned_semantic / learned_semantic: Semantic match on learned phrases
+- semantic: Embedding similarity from verb_pattern_embeddings (primary lookup)
 
 Use this BEFORE dsl_generate to understand available verbs.
-The learning system improves over time - Day 1 ~70% hit rate, Day 30 ~90%+."#.into(),
+The learning system improves over time as user corrections accumulate."#.into(),
             input_schema: json!({
                 "type": "object",
                 "properties": {
@@ -331,7 +334,7 @@ The system will:
             description: r#"Generate DSL from natural language using structured intent extraction.
 
 PIPELINE:
-1. verb_search finds matching verbs (learned → phrase → semantic)
+1. verb_search finds matching verbs (learned → semantic via pgvector)
 2. LLM extracts argument values as JSON (NEVER writes DSL syntax)
 3. DSL assembled deterministically from structured intent
 4. Validated before return
@@ -2466,5 +2469,76 @@ Use this after:
                 "properties": {}
             }),
         },
+        // =====================================================================
+        // Learning System Tools
+        // =====================================================================
+        Tool {
+            name: "learning_analyze".into(),
+            description: r#"Analyze user feedback to discover learnable patterns.
+
+Runs feedback analysis to find:
+- Pattern discoveries: user inputs that led to successful executions
+- Confusion pairs: verb A matched but user wanted verb B
+- Gaps: inputs where matching failed or had low confidence
+- Low-score successes: patterns that worked despite low match scores
+
+Returns analysis report without applying changes. Use learning_apply to apply."#.into(),
+            input_schema: json!({
+                "type": "object",
+                "properties": {
+                    "days_back": {
+                        "type": "integer",
+                        "default": 7,
+                        "description": "Days of feedback history to analyze"
+                    }
+                }
+            }),
+        },
+        Tool {
+            name: "learning_apply".into(),
+            description: r#"Apply discovered patterns to improve verb matching.
+
+Runs analysis and auto-applies high-confidence pattern discoveries:
+- Patterns seen 5+ times (configurable)
+- Average match score > 0.5
+- Adds patterns to dsl_verbs.intent_patterns
+
+After applying, run embeddings_status to check if re-embedding is needed."#.into(),
+            input_schema: json!({
+                "type": "object",
+                "properties": {
+                    "days_back": {
+                        "type": "integer",
+                        "default": 7,
+                        "description": "Days of feedback history to analyze"
+                    },
+                    "min_occurrences": {
+                        "type": "integer",
+                        "default": 5,
+                        "description": "Minimum occurrences to auto-apply a pattern"
+                    }
+                }
+            }),
+        },
+        Tool {
+            name: "embeddings_status".into(),
+            description: r#"Check embedding coverage for verb patterns.
+
+Reports:
+- Total patterns from v_verb_intent_patterns (YAML + learned combined)
+- Patterns with embeddings in verb_pattern_embeddings
+- Pending patterns (need embedding)
+- Whether re-embedding is recommended
+
+Pattern sources:
+- yaml_intent_patterns: from YAML invocation_phrases (overwritten on startup)
+- intent_patterns: learned from user feedback (preserved across restarts)
+
+If pending > 0, run: cargo run --release --bin populate_embeddings"#.into(),
+            input_schema: json!({
+                "type": "object",
+                "properties": {}
+            }),
+        },
     ]
 }
diff --git a/rust/src/mcp/verb_search.rs b/rust/src/mcp/verb_search.rs
index 4f7705ae..1209fd74 100644
--- a/rust/src/mcp/verb_search.rs
+++ b/rust/src/mcp/verb_search.rs
@@ -9,9 +9,17 @@
 //! 6. Global semantic via verb_pattern_embeddings - PRIMARY LOOKUP
 //!
 //! Architecture (DB as source of truth):
-//!   YAML invocation_phrases → VerbSyncService → dsl_verbs.intent_patterns
+//!
+//!   Pattern sources (two columns in dsl_verbs):
+//!   - yaml_intent_patterns: from YAML invocation_phrases (overwritten on startup)
+//!   - intent_patterns: learned from user feedback (preserved across restarts)
+//!
+//!   YAML invocation_phrases → VerbSyncService → dsl_verbs.yaml_intent_patterns
+//!   Learning loop feedback  → PatternLearner  → dsl_verbs.intent_patterns
+//!                                                       ↓
+//!   v_verb_intent_patterns (UNION of both) → populate_embeddings binary
 //!                                                       ↓
-//!   populate_embeddings binary → verb_pattern_embeddings (with Candle vectors)
+//!   verb_pattern_embeddings (Candle 384-dim vectors)
 //!                                                       ↓
 //!   HybridVerbSearcher.search_global_semantic() ← PRIMARY SEMANTIC LOOKUP
 //!
diff --git a/rust/src/session/verb_sync.rs b/rust/src/session/verb_sync.rs
index bfab5ba8..26a02139 100644
--- a/rust/src/session/verb_sync.rs
+++ b/rust/src/session/verb_sync.rs
@@ -218,6 +218,13 @@ impl VerbSyncService {
     ///
     /// This makes dsl_verbs.intent_patterns the source of truth for the Candle semantic pipeline.
     /// After sync, run `populate_embeddings` to update verb_pattern_embeddings.
+    /// Sync invocation_phrases from YAML to yaml_intent_patterns column
+    ///
+    /// IMPORTANT: This updates yaml_intent_patterns (not intent_patterns).
+    /// - yaml_intent_patterns: YAML-sourced, safe to overwrite on startup
+    /// - intent_patterns: Learned patterns, preserved across restarts
+    ///
+    /// The v_verb_intent_patterns view unions both for embedding.
     pub async fn sync_invocation_phrases(
         &self,
         config: &VerbsConfig,
@@ -233,11 +240,11 @@ impl VerbSyncService {
                     continue;
                 }
 
-                // Update intent_patterns in dsl_verbs
+                // Update yaml_intent_patterns (NOT intent_patterns which holds learned patterns)
                 let result = sqlx::query(
                     r#"
                     UPDATE "ob-poc".dsl_verbs
-                    SET intent_patterns = $2,
+                    SET yaml_intent_patterns = $2,
                         updated_at = now()
                     WHERE full_name = $1
                     "#,
diff --git a/schema_export.sql b/schema_export.sql
index fa483bbb..af3cdc9b 100644
--- a/schema_export.sql
+++ b/schema_export.sql
@@ -477,7 +477,7 @@ $$;
 CREATE FUNCTION kyc.check_case_doc_completion(p_case_id uuid) RETURNS TABLE(total_requests integer, pending_requests integer, received_requests integer, verified_requests integer, mandatory_pending integer, all_mandatory_complete boolean)
     LANGUAGE sql STABLE
     AS $$
-SELECT 
+SELECT
     COUNT(*)::INTEGER as total_requests,
     COUNT(*) FILTER (WHERE dr.status IN ('REQUIRED', 'REQUESTED'))::INTEGER as pending_requests,
     COUNT(*) FILTER (WHERE dr.status = 'RECEIVED')::INTEGER as received_requests,
@@ -855,19 +855,19 @@ BEGIN
     IF v_cbu_id IS NULL THEN
         RAISE EXCEPTION 'Case not found: %', p_case_id;
     END IF;
-    
+
     -- Generate batch reference if not provided
-    v_batch_ref := COALESCE(p_batch_reference, 
+    v_batch_ref := COALESCE(p_batch_reference,
         'RFI-' || TO_CHAR(NOW(), 'YYYYMMDD') || '-' || LEFT(v_batch_id::TEXT, 8));
-    
+
     -- Get risk band for CBU
     SELECT COALESCE(
         (SELECT risk_band FROM "ob-poc".compute_cbu_risk_score(v_cbu_id)),
         'MEDIUM'
     ) INTO v_risk_band;
-    
+
     -- Process each workstream in the case
-    FOR v_workstream IN 
+    FOR v_workstream IN
         SELECT w.workstream_id, w.entity_id, e.name as entity_name,
                array_agg(DISTINCT r.name) FILTER (WHERE r.name IS NOT NULL) as roles
         FROM kyc.entity_workstreams w
@@ -878,14 +878,14 @@ BEGIN
         GROUP BY w.workstream_id, w.entity_id, e.name
     LOOP
         v_entities_processed := v_entities_processed + 1;
-        
+
         -- Get missing requirements for this entity's roles
         FOR v_requirement IN
             SELECT tr.requirement_id, tr.requirement_type, tr.entity_role,
                    tr.document_count_required, tr.is_mandatory
             FROM "ob-poc".threshold_requirements tr
             JOIN "ob-poc".risk_bands rb ON tr.risk_band_id = rb.risk_band_id
-            WHERE rb.band_code = v_risk_band 
+            WHERE rb.band_code = v_risk_band
             AND tr.entity_role = ANY(v_workstream.roles)
             AND tr.is_mandatory = true
             AND NOT EXISTS (
@@ -919,17 +919,17 @@ BEGIN
                 'THRESHOLD',
                 CURRENT_DATE + INTERVAL '14 days'
             ) RETURNING request_id INTO v_request_id;
-            
+
             -- Link acceptable document types
             INSERT INTO kyc.doc_request_acceptable_types (request_id, document_type_id)
             SELECT v_request_id, rad.document_type_id
             FROM "ob-poc".requirement_acceptable_docs rad
             WHERE rad.requirement_id = v_requirement.requirement_id;
-            
+
             v_requests_created := v_requests_created + 1;
         END LOOP;
     END LOOP;
-    
+
     RETURN QUERY SELECT v_batch_id, v_requests_created, v_entities_processed;
 END;
 $$;
@@ -1321,19 +1321,19 @@ BEGIN
     -- Get current case status
     SELECT status INTO v_current_status
     FROM kyc.cases WHERE case_id = p_case_id;
-    
+
     -- Get latest evaluation
     SELECT * INTO v_latest_eval
     FROM "ob-poc".case_evaluation_snapshots
     WHERE case_id = p_case_id
     ORDER BY evaluated_at DESC
     LIMIT 1;
-    
+
     -- Validate decision against recommendation
     IF v_latest_eval.has_hard_stop AND p_decision NOT IN ('DO_NOT_ONBOARD', 'REJECT', 'REFER_TO_REGULATOR') THEN
         RAISE EXCEPTION 'Cannot approve case with unresolved hard stops. Recommended: %', v_latest_eval.recommended_action;
     END IF;
-    
+
     -- Map decision to case status
     v_new_status := CASE p_decision
         WHEN 'APPROVE' THEN 'APPROVED'
@@ -1344,7 +1344,7 @@ BEGIN
         WHEN 'ESCALATE' THEN 'REVIEW'  -- Stay in review but escalate
         ELSE v_current_status
     END;
-    
+
     -- Update evaluation snapshot with decision
     UPDATE "ob-poc".case_evaluation_snapshots
     SET decision_made = p_decision,
@@ -1352,14 +1352,14 @@ BEGIN
         decision_made_by = p_decided_by,
         decision_notes = p_notes
     WHERE snapshot_id = v_latest_eval.snapshot_id;
-    
+
     -- Update case status if changed
     IF v_new_status != v_current_status THEN
         UPDATE kyc.cases
         SET status = v_new_status,
             last_activity_at = now()
         WHERE case_id = p_case_id;
-        
+
         -- If closing, set closed_at
         IF v_new_status IN ('APPROVED', 'REJECTED', 'DO_NOT_ONBOARD') THEN
             UPDATE kyc.cases
@@ -1367,12 +1367,12 @@ BEGIN
             WHERE case_id = p_case_id;
         END IF;
     END IF;
-    
+
     -- Log case event
     INSERT INTO kyc.case_events (
         case_id, event_type, event_data, actor_type, comment
     ) VALUES (
-        p_case_id, 
+        p_case_id,
         'DECISION_APPLIED',
         jsonb_build_object(
             'decision', p_decision,
@@ -1385,7 +1385,7 @@ BEGIN
         'USER',
         p_notes
     );
-    
+
     RETURN true;
 END;
 $$;
@@ -1419,7 +1419,7 @@ BEGIN
           AND evidence_role = 'IDENTITY_PROOF'
           AND verification_status = 'VERIFIED'
     ) INTO v_has_identity;
-    
+
     -- Check for ownership proof
     SELECT EXISTS (
         SELECT 1 FROM "ob-poc".ubo_evidence
@@ -1427,15 +1427,15 @@ BEGIN
           AND evidence_role IN ('OWNERSHIP_PROOF', 'CHAIN_LINK')
           AND verification_status = 'VERIFIED'
     ) INTO v_has_ownership;
-    
+
     -- Count evidence
-    SELECT 
+    SELECT
         COUNT(*) FILTER (WHERE verification_status = 'VERIFIED'),
         COUNT(*) FILTER (WHERE verification_status = 'PENDING')
     INTO v_verified_count, v_pending_count
     FROM "ob-poc".ubo_evidence
     WHERE ubo_id = p_ubo_id;
-    
+
     -- Build missing list
     IF NOT v_has_identity THEN
         v_missing := array_append(v_missing, 'IDENTITY_PROOF');
@@ -1443,8 +1443,8 @@ BEGIN
     IF NOT v_has_ownership THEN
         v_missing := array_append(v_missing, 'OWNERSHIP_PROOF');
     END IF;
-    
-    RETURN QUERY SELECT 
+
+    RETURN QUERY SELECT
         (v_has_identity AND v_has_ownership),
         v_has_identity,
         v_has_ownership,
@@ -1492,7 +1492,7 @@ BEGIN
     WHERE ur.cbu_id = p_cbu_id
       AND ur.superseded_at IS NULL
       AND ur.closed_at IS NULL;
-    
+
     -- Get ownership chains
     SELECT COALESCE(jsonb_agg(jsonb_build_object(
         'ubo_person_id', chain.ubo_person_id,
@@ -1505,7 +1505,7 @@ BEGIN
     )), '[]'::JSONB)
     INTO v_chains
     FROM "ob-poc".compute_ownership_chains(p_cbu_id) chain;
-    
+
     -- Get control relationships
     SELECT COALESCE(jsonb_agg(jsonb_build_object(
         'control_id', cr.control_id,
@@ -1519,11 +1519,11 @@ BEGIN
     JOIN "ob-poc".cbu_entity_roles cer ON cr.controlled_entity_id = cer.entity_id
     WHERE cer.cbu_id = p_cbu_id
       AND cr.is_active = true;
-    
+
     -- Check completeness
     SELECT * INTO v_completeness
     FROM "ob-poc".check_ubo_completeness(p_cbu_id);
-    
+
     -- Insert snapshot
     INSERT INTO "ob-poc".ubo_snapshots (
         cbu_id, case_id, snapshot_type, snapshot_reason,
@@ -1535,12 +1535,12 @@ BEGIN
         v_ubos, v_chains, v_controls,
         v_completeness.total_identified_ownership,
         NOT v_completeness.is_complete,
-        CASE WHEN NOT v_completeness.is_complete 
-             THEN v_completeness.issues::TEXT 
+        CASE WHEN NOT v_completeness.is_complete
+             THEN v_completeness.issues::TEXT
              ELSE NULL END,
         p_captured_by
     ) RETURNING snapshot_id INTO v_snapshot_id;
-    
+
     RETURN v_snapshot_id;
 END;
 $$;
@@ -1722,14 +1722,14 @@ DECLARE
     v_rejected_count INTEGER;
 BEGIN
     -- Count evidence by status
-    SELECT 
+    SELECT
         COUNT(*) FILTER (WHERE verification_status = 'VERIFIED'),
         COUNT(*) FILTER (WHERE verification_status = 'PENDING'),
         COUNT(*) FILTER (WHERE verification_status = 'REJECTED')
     INTO v_verified_count, v_pending_count, v_rejected_count
     FROM "ob-poc".cbu_evidence
     WHERE cbu_id = p_cbu_id;
-    
+
     -- Get verified categories
     SELECT ARRAY_AGG(DISTINCT evidence_category)
     INTO v_verified_categories
@@ -1737,13 +1737,13 @@ BEGIN
     WHERE cbu_id = p_cbu_id
       AND verification_status = 'VERIFIED'
       AND evidence_category IS NOT NULL;
-    
+
     -- Handle NULL array
     IF v_verified_categories IS NULL THEN
         v_verified_categories := ARRAY[]::TEXT[];
     END IF;
-    
-    RETURN QUERY SELECT 
+
+    RETURN QUERY SELECT
         v_required_categories <@ v_verified_categories,  -- All required present in verified
         ARRAY(
             SELECT unnest(v_required_categories)
@@ -1774,7 +1774,7 @@ CREATE FUNCTION "ob-poc".check_cbu_invariants() RETURNS TABLE(cbu_id uuid, cbu_n
 BEGIN
     -- Check 1: commercial_client_entity_id without matching role
     RETURN QUERY
-    SELECT 
+    SELECT
         c.cbu_id,
         c.name,
         'COMMERCIAL_CLIENT_ROLE_MISSING'::VARCHAR,
@@ -1784,34 +1784,34 @@ BEGIN
       AND NOT EXISTS (
           SELECT 1 FROM "ob-poc".cbu_entity_roles cer
           JOIN "ob-poc".roles r ON cer.role_id = r.role_id
-          WHERE cer.cbu_id = c.cbu_id 
+          WHERE cer.cbu_id = c.cbu_id
             AND cer.entity_id = c.commercial_client_entity_id
             AND r.name = 'COMMERCIAL_CLIENT'
       );
-    
+
     -- Check 2: CBU with no cbu_category
     RETURN QUERY
-    SELECT 
+    SELECT
         c.cbu_id,
         c.name,
         'MISSING_CATEGORY'::VARCHAR,
         'cbu_category is NULL'::TEXT
     FROM "ob-poc".cbus c
     WHERE c.cbu_category IS NULL;
-    
+
     -- Check 3: CBU with no jurisdiction
     RETURN QUERY
-    SELECT 
+    SELECT
         c.cbu_id,
         c.name,
         'MISSING_JURISDICTION'::VARCHAR,
         'jurisdiction is NULL'::TEXT
     FROM "ob-poc".cbus c
     WHERE c.jurisdiction IS NULL;
-    
+
     -- Check 4: Active CBU with no entities (has KYC case but no entity roles)
     RETURN QUERY
-    SELECT 
+    SELECT
         c.cbu_id,
         c.name,
         'NO_ENTITIES_ASSIGNED'::VARCHAR,
@@ -1819,7 +1819,7 @@ BEGIN
     FROM "ob-poc".cbus c
     WHERE EXISTS (SELECT 1 FROM kyc.cases kc WHERE kc.cbu_id = c.cbu_id)
       AND NOT EXISTS (SELECT 1 FROM "ob-poc".cbu_entity_roles cer WHERE cer.cbu_id = c.cbu_id);
-    
+
 END;
 $$;
 
@@ -1846,15 +1846,15 @@ BEGIN
         JOIN "ob-poc".roles r ON cer.role_id = r.role_id
         WHERE cer.cbu_id = p_cbu_id
     )
-    SELECT 
+    SELECT
         rr.requirement_type,
         rr.requiring_role,
         rr.required_role,
         EXISTS (SELECT 1 FROM cbu_roles WHERE role_name = rr.required_role) AS is_satisfied,
-        CASE 
+        CASE
             WHEN EXISTS (SELECT 1 FROM cbu_roles WHERE role_name = rr.required_role)
             THEN format('Requirement satisfied: %s present', rr.required_role)
-            ELSE format('Missing required role %s for %s: %s', 
+            ELSE format('Missing required role %s for %s: %s',
                         rr.required_role, rr.requiring_role, rr.condition_description)
         END AS message
     FROM "ob-poc".role_requirements rr
@@ -1888,13 +1888,13 @@ BEGIN
     SELECT COALESCE(SUM(DISTINCT effective_ownership), 0)
     INTO v_total_ownership
     FROM "ob-poc".compute_ownership_chains(p_cbu_id);
-    
+
     -- Count UBOs above threshold
     SELECT COUNT(DISTINCT ubo_person_id)
     INTO v_ubos_count
     FROM "ob-poc".compute_ownership_chains(p_cbu_id)
     WHERE effective_ownership >= p_threshold;
-    
+
     -- Check for incomplete chains (entities with no further ownership but not persons)
     SELECT COUNT(*)
     INTO v_incomplete_chains
@@ -1907,7 +1907,7 @@ BEGIN
       AND o.is_active = true
       AND parent.ownership_id IS NULL
       AND et.type_code != 'proper_person';
-    
+
     -- Build issues array
     IF v_total_ownership < 100 THEN
         v_issues := v_issues || jsonb_build_object(
@@ -1916,7 +1916,7 @@ BEGIN
             'gap', 100 - v_total_ownership
         );
     END IF;
-    
+
     IF v_incomplete_chains > 0 THEN
         v_issues := v_issues || jsonb_build_object(
             'type', 'INCOMPLETE_CHAIN',
@@ -1924,7 +1924,7 @@ BEGIN
             'count', v_incomplete_chains
         );
     END IF;
-    
+
     RETURN QUERY SELECT
         (v_total_ownership >= 100 AND v_incomplete_chains = 0),
         v_total_ownership,
@@ -2088,13 +2088,13 @@ BEGIN
     -- Get weights from config
     SELECT weight INTO v_soft_weight FROM "ob-poc".redflag_score_config WHERE severity = 'SOFT';
     SELECT weight INTO v_escalate_weight FROM "ob-poc".redflag_score_config WHERE severity = 'ESCALATE';
-    
+
     -- Default weights if not configured
     v_soft_weight := COALESCE(v_soft_weight, 1);
     v_escalate_weight := COALESCE(v_escalate_weight, 2);
-    
+
     RETURN QUERY
-    SELECT 
+    SELECT
         COUNT(*) FILTER (WHERE rf.severity = 'SOFT')::INTEGER as soft_count,
         COUNT(*) FILTER (WHERE rf.severity = 'ESCALATE')::INTEGER as escalate_count,
         COUNT(*) FILTER (WHERE rf.severity = 'HARD_STOP')::INTEGER as hard_stop_count,
@@ -2104,7 +2104,7 @@ BEGIN
         (
             COUNT(*) FILTER (WHERE rf.severity = 'SOFT' AND rf.status = 'OPEN') * v_soft_weight +
             COUNT(*) FILTER (WHERE rf.severity = 'ESCALATE' AND rf.status = 'OPEN') * v_escalate_weight +
-            CASE WHEN COUNT(*) FILTER (WHERE rf.severity = 'HARD_STOP' AND rf.status IN ('OPEN', 'BLOCKING')) > 0 
+            CASE WHEN COUNT(*) FILTER (WHERE rf.severity = 'HARD_STOP' AND rf.status IN ('OPEN', 'BLOCKING')) > 0
                  THEN 1000 ELSE 0 END
         )::INTEGER as total_score,
         COUNT(*) FILTER (WHERE rf.status = 'OPEN')::INTEGER as open_flags,
@@ -2151,7 +2151,7 @@ BEGIN
         SELECT * INTO v_factor
         FROM "ob-poc".threshold_factors
         WHERE factor_type = 'CBU_TYPE' AND factor_code = v_cbu.client_type AND is_active = true;
-        
+
         IF FOUND THEN
             v_score := v_score + v_factor.risk_weight;
             v_factors := v_factors || jsonb_build_object('type', v_factor.factor_type, 'code', v_factor.factor_code, 'weight', v_factor.risk_weight);
@@ -2163,7 +2163,7 @@ BEGIN
         SELECT * INTO v_factor
         FROM "ob-poc".threshold_factors
         WHERE factor_type = 'SOURCE_OF_FUNDS' AND factor_code = v_cbu.source_of_funds AND is_active = true;
-        
+
         IF FOUND THEN
             v_score := v_score + v_factor.risk_weight;
             v_factors := v_factors || jsonb_build_object('type', v_factor.factor_type, 'code', v_factor.factor_code, 'weight', v_factor.risk_weight);
@@ -2175,7 +2175,7 @@ BEGIN
         SELECT * INTO v_factor
         FROM "ob-poc".threshold_factors
         WHERE factor_type = 'NATURE_PURPOSE' AND factor_code = v_cbu.nature_purpose AND is_active = true;
-        
+
         IF FOUND THEN
             v_score := v_score + v_factor.risk_weight;
             v_factors := v_factors || jsonb_build_object('type', v_factor.factor_type, 'code', v_factor.factor_code, 'weight', v_factor.risk_weight);
@@ -2381,7 +2381,7 @@ BEGIN
     -- Get current scores
     SELECT * INTO v_scores
     FROM "ob-poc".compute_case_redflag_score(p_case_id);
-    
+
     -- Find matching threshold (priority: hard_stop > escalate > score-based)
     IF v_scores.has_hard_stop THEN
         SELECT * INTO v_threshold
@@ -2403,7 +2403,7 @@ BEGIN
         ORDER BY COALESCE(min_score, 0) DESC
         LIMIT 1;
     END IF;
-    
+
     -- Create evaluation snapshot
     INSERT INTO "ob-poc".case_evaluation_snapshots (
         case_id,
@@ -2420,7 +2420,7 @@ BEGIN
         v_threshold.threshold_id, v_threshold.recommended_action, v_threshold.escalation_level,
         p_evaluator
     ) RETURNING snapshot_id INTO v_snapshot_id;
-    
+
     RETURN v_snapshot_id;
 END;
 $$;
@@ -2493,7 +2493,7 @@ COMMENT ON FUNCTION "ob-poc".find_idempotency_by_verb_hash(p_verb_hash bytea, p_
 CREATE FUNCTION "ob-poc".find_phonetic_matches(query_phonetic_codes text[], top_k integer DEFAULT 5) RETURNS TABLE(verb_name character varying, pattern_phrase text, category character varying, is_agent_bound boolean, priority integer, matching_codes text[])
     LANGUAGE sql STABLE
     AS $$
-    SELECT 
+    SELECT
         vpe.verb_name,
         vpe.pattern_phrase,
         vpe.category,
@@ -2502,7 +2502,7 @@ CREATE FUNCTION "ob-poc".find_phonetic_matches(query_phonetic_codes text[], top_
         ARRAY(SELECT unnest(vpe.phonetic_codes) INTERSECT SELECT unnest(query_phonetic_codes)) AS matching_codes
     FROM "ob-poc".verb_pattern_embeddings vpe
     WHERE vpe.phonetic_codes && query_phonetic_codes
-    ORDER BY 
+    ORDER BY
         array_length(ARRAY(SELECT unnest(vpe.phonetic_codes) INTERSECT SELECT unnest(query_phonetic_codes)), 1) DESC NULLS LAST,
         vpe.priority
     LIMIT top_k;
@@ -2789,19 +2789,19 @@ BEGIN
     IF p_from_status = p_to_status THEN
         RETURN true;
     END IF;
-    
+
     RETURN CASE p_from_status
-        WHEN 'DISCOVERED' THEN 
+        WHEN 'DISCOVERED' THEN
             p_to_status IN ('VALIDATION_PENDING', 'VALIDATION_FAILED')
-        WHEN 'VALIDATION_PENDING' THEN 
+        WHEN 'VALIDATION_PENDING' THEN
             p_to_status IN ('VALIDATED', 'VALIDATION_FAILED', 'DISCOVERED')
-        WHEN 'VALIDATED' THEN 
+        WHEN 'VALIDATED' THEN
             p_to_status IN ('UPDATE_PENDING_PROOF')  -- Material change triggers re-validation
-        WHEN 'UPDATE_PENDING_PROOF' THEN 
+        WHEN 'UPDATE_PENDING_PROOF' THEN
             p_to_status IN ('VALIDATED', 'VALIDATION_FAILED')
-        WHEN 'VALIDATION_FAILED' THEN 
+        WHEN 'VALIDATION_FAILED' THEN
             p_to_status IN ('VALIDATION_PENDING', 'DISCOVERED')  -- Retry or start over
-        ELSE 
+        ELSE
             false
     END;
 END;
@@ -2827,28 +2827,28 @@ BEGIN
     IF p_from_status = p_to_status THEN
         RETURN true;
     END IF;
-    
+
     -- Handle NULL (new record) - can start as SUSPECTED or PENDING
     IF p_from_status IS NULL THEN
         RETURN p_to_status IN ('SUSPECTED', 'PENDING');
     END IF;
-    
+
     RETURN CASE p_from_status
-        WHEN 'SUSPECTED' THEN 
+        WHEN 'SUSPECTED' THEN
             p_to_status IN ('PROVEN', 'PENDING', 'FAILED', 'REMOVED')
-        WHEN 'PENDING' THEN 
+        WHEN 'PENDING' THEN
             p_to_status IN ('PROVEN', 'VERIFIED', 'FAILED', 'DISPUTED', 'REMOVED')
-        WHEN 'PROVEN' THEN 
+        WHEN 'PROVEN' THEN
             p_to_status IN ('VERIFIED', 'DISPUTED', 'REMOVED')
-        WHEN 'VERIFIED' THEN 
+        WHEN 'VERIFIED' THEN
             p_to_status IN ('DISPUTED', 'REMOVED')  -- Can be challenged or ownership changes
-        WHEN 'FAILED' THEN 
+        WHEN 'FAILED' THEN
             p_to_status IN ('SUSPECTED', 'PENDING')  -- Retry
-        WHEN 'DISPUTED' THEN 
+        WHEN 'DISPUTED' THEN
             p_to_status IN ('PROVEN', 'VERIFIED', 'REMOVED', 'FAILED')  -- Resolution
-        WHEN 'REMOVED' THEN 
+        WHEN 'REMOVED' THEN
             false  -- Terminal state
-        ELSE 
+        ELSE
             false
     END;
 END;
@@ -2874,8 +2874,8 @@ BEGIN
         INSERT INTO "ob-poc".cbu_change_log (
             cbu_id, change_type, field_name, old_value, new_value, changed_at
         ) VALUES (
-            NEW.cbu_id, 
-            'STATUS_CHANGE', 
+            NEW.cbu_id,
+            'STATUS_CHANGE',
             'status',
             to_jsonb(OLD.status),
             to_jsonb(NEW.status),
@@ -4226,7 +4226,7 @@ BEGIN
     IF NEW.commercial_client_entity_id IS NOT NULL THEN
         -- Ensure role exists (upsert)
         INSERT INTO "ob-poc".cbu_entity_roles (cbu_id, entity_id, role_id)
-        SELECT 
+        SELECT
             NEW.cbu_id,
             NEW.commercial_client_entity_id,
             r.role_id
@@ -4234,18 +4234,18 @@ BEGIN
         WHERE r.name = 'COMMERCIAL_CLIENT'
         ON CONFLICT (cbu_id, entity_id, role_id) DO NOTHING;
     END IF;
-    
+
     -- If commercial_client_entity_id is being cleared
-    IF OLD IS NOT NULL 
-       AND OLD.commercial_client_entity_id IS NOT NULL 
+    IF OLD IS NOT NULL
+       AND OLD.commercial_client_entity_id IS NOT NULL
        AND (NEW.commercial_client_entity_id IS NULL OR NEW.commercial_client_entity_id != OLD.commercial_client_entity_id) THEN
         -- Remove old role
-        DELETE FROM "ob-poc".cbu_entity_roles 
-        WHERE cbu_id = NEW.cbu_id 
+        DELETE FROM "ob-poc".cbu_entity_roles
+        WHERE cbu_id = NEW.cbu_id
           AND entity_id = OLD.commercial_client_entity_id
           AND role_id = (SELECT role_id FROM "ob-poc".roles WHERE name = 'COMMERCIAL_CLIENT');
     END IF;
-    
+
     RETURN NEW;
 END;
 $$;
@@ -4498,7 +4498,7 @@ BEGIN
         sort_order = EXCLUDED.sort_order,
         updated_at = NOW()
     RETURNING role_id INTO v_role_id;
-    
+
     RETURN v_role_id;
 END;
 $$;
@@ -4520,24 +4520,24 @@ BEGIN
     -- Get role details
     SELECT * INTO v_role FROM "ob-poc".roles WHERE name = UPPER(p_role_name);
     IF NOT FOUND THEN
-        RETURN QUERY SELECT FALSE, 'ROLE_NOT_FOUND'::VARCHAR(50), 
+        RETURN QUERY SELECT FALSE, 'ROLE_NOT_FOUND'::VARCHAR(50),
             format('Role %s does not exist', p_role_name);
         RETURN;
     END IF;
-    
+
     -- Get entity details
     SELECT e.entity_id, e.name, et.entity_category, et.type_code
     INTO v_entity
     FROM "ob-poc".entities e
     JOIN "ob-poc".entity_types et ON e.entity_type_id = et.entity_type_id
     WHERE e.entity_id = p_entity_id;
-    
+
     IF NOT FOUND THEN
         RETURN QUERY SELECT FALSE, 'ENTITY_NOT_FOUND'::VARCHAR(50),
             format('Entity %s does not exist', p_entity_id);
         RETURN;
     END IF;
-    
+
     -- Check natural person constraint
     IF v_role.natural_person_only AND v_entity.entity_category != 'PERSON' THEN
         RETURN QUERY SELECT FALSE, 'NATURAL_PERSON_REQUIRED'::VARCHAR(50),
@@ -4545,7 +4545,7 @@ BEGIN
                    p_role_name, v_entity.name, v_entity.entity_category);
         RETURN;
     END IF;
-    
+
     -- Check legal entity constraint
     IF v_role.legal_entity_only AND v_entity.entity_category = 'PERSON' THEN
         RETURN QUERY SELECT FALSE, 'LEGAL_ENTITY_REQUIRED'::VARCHAR(50),
@@ -4553,7 +4553,7 @@ BEGIN
                    p_role_name, v_entity.name);
         RETURN;
     END IF;
-    
+
     -- Check entity category compatibility
     IF v_role.compatible_entity_categories IS NOT NULL THEN
         IF NOT (v_role.compatible_entity_categories ? v_entity.entity_category) THEN
@@ -4563,13 +4563,13 @@ BEGIN
             RETURN;
         END IF;
     END IF;
-    
+
     -- Get existing roles for this entity in this CBU
     SELECT array_agg(r.name) INTO v_existing_roles
     FROM "ob-poc".cbu_entity_roles cer
     JOIN "ob-poc".roles r ON cer.role_id = r.role_id
     WHERE cer.entity_id = p_entity_id AND cer.cbu_id = p_cbu_id;
-    
+
     -- Check for incompatible role combinations
     FOR v_incompatible IN
         SELECT ri.role_a, ri.role_b, ri.reason, ri.exception_allowed
@@ -4596,7 +4596,7 @@ BEGIN
             END IF;
         END IF;
     END LOOP;
-    
+
     -- All checks passed
     RETURN QUERY SELECT TRUE, NULL::VARCHAR(50), NULL::TEXT;
 END;
@@ -4620,10 +4620,10 @@ CREATE FUNCTION "ob-poc".validate_ubo_status_transition() RETURNS trigger
 BEGIN
     IF OLD.verification_status IS DISTINCT FROM NEW.verification_status THEN
         IF NOT "ob-poc".is_valid_ubo_transition(OLD.verification_status, NEW.verification_status) THEN
-            RAISE EXCEPTION 'Invalid UBO status transition from % to %', 
+            RAISE EXCEPTION 'Invalid UBO status transition from % to %',
                 OLD.verification_status, NEW.verification_status;
         END IF;
-        
+
         -- If transitioning to PROVEN, check evidence requirements
         IF NEW.verification_status = 'PROVEN' THEN
             DECLARE
@@ -4631,20 +4631,20 @@ BEGIN
             BEGIN
                 SELECT can_prove INTO v_can_prove
                 FROM "ob-poc".can_prove_ubo(NEW.ubo_id);
-                
+
                 IF NOT v_can_prove THEN
                     RAISE WARNING 'UBO % marked as PROVEN without complete evidence', NEW.ubo_id;
                     -- Note: Warning only, not blocking - allows override
                 END IF;
             END;
         END IF;
-        
+
         -- Set proof_date when transitioning to PROVEN
         IF NEW.verification_status = 'PROVEN' AND NEW.proof_date IS NULL THEN
             NEW.proof_date := now();
         END IF;
     END IF;
-    
+
     RETURN NEW;
 END;
 $$;
@@ -9981,6 +9981,7 @@ CREATE TABLE "ob-poc".dsl_verbs (
     category text,
     search_text text,
     intent_patterns text[],
+    yaml_intent_patterns text[] DEFAULT ARRAY[]::text[],
     workflow_phases text[],
     graph_contexts text[],
     example_short text,
@@ -10054,6 +10055,20 @@ COMMENT ON COLUMN "ob-poc".dsl_verbs.compiler_version IS 'Semantic version of th
 COMMENT ON COLUMN "ob-poc".dsl_verbs.compiled_at IS 'Timestamp when compiled_json was last generated (NULL if never compiled)';
 
 
+--
+-- Name: COLUMN dsl_verbs.yaml_intent_patterns; Type: COMMENT; Schema: ob-poc; Owner: -
+--
+
+COMMENT ON COLUMN "ob-poc".dsl_verbs.yaml_intent_patterns IS 'Intent patterns from YAML invocation_phrases - synced on startup, safe to overwrite';
+
+
+--
+-- Name: COLUMN dsl_verbs.intent_patterns; Type: COMMENT; Schema: ob-poc; Owner: -
+--
+
+COMMENT ON COLUMN "ob-poc".dsl_verbs.intent_patterns IS 'Learned intent patterns from feedback loop - NOT overwritten on startup';
+
+
 --
 -- Name: dsl_view_state_changes; Type: TABLE; Schema: ob-poc; Owner: -
 --
@@ -14371,6 +14386,72 @@ CREATE VIEW "ob-poc".v_verbs_needing_recompile AS
 COMMENT ON VIEW "ob-poc".v_verbs_needing_recompile IS 'Shows verbs that may need recompilation with current compiler version';
 
 
+--
+-- Name: v_verb_intent_patterns; Type: VIEW; Schema: ob-poc; Owner: -
+--
+
+CREATE VIEW "ob-poc".v_verb_intent_patterns AS
+SELECT
+    v.full_name as verb_full_name,
+    pattern,
+    COALESCE(m.category, 'general') as category,
+    m.is_agent_bound,
+    COALESCE(m.priority, 1) as priority,
+    'yaml' as source
+FROM "ob-poc".dsl_verbs v
+CROSS JOIN LATERAL unnest(v.yaml_intent_patterns) as pattern
+LEFT JOIN "ob-poc".verb_metadata m ON m.verb_full_name = v.full_name
+WHERE v.yaml_intent_patterns IS NOT NULL
+  AND array_length(v.yaml_intent_patterns, 1) > 0
+
+UNION ALL
+
+SELECT
+    v.full_name as verb_full_name,
+    pattern,
+    COALESCE(m.category, 'general') as category,
+    m.is_agent_bound,
+    COALESCE(m.priority, 2) as priority,
+    'learned' as source
+FROM "ob-poc".dsl_verbs v
+CROSS JOIN LATERAL unnest(v.intent_patterns) as pattern
+LEFT JOIN "ob-poc".verb_metadata m ON m.verb_full_name = v.full_name
+WHERE v.intent_patterns IS NOT NULL
+  AND array_length(v.intent_patterns, 1) > 0;
+
+
+--
+-- Name: VIEW v_verb_intent_patterns; Type: COMMENT; Schema: ob-poc; Owner: -
+--
+
+COMMENT ON VIEW "ob-poc".v_verb_intent_patterns IS 'Flattened view of all intent patterns (YAML + learned) for embedding population';
+
+
+--
+-- Name: v_verb_embedding_stats; Type: VIEW; Schema: ob-poc; Owner: -
+--
+
+CREATE VIEW "ob-poc".v_verb_embedding_stats AS
+SELECT
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs) as total_verbs,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE (yaml_intent_patterns IS NOT NULL AND array_length(yaml_intent_patterns, 1) > 0)
+        OR (intent_patterns IS NOT NULL AND array_length(intent_patterns, 1) > 0)) as verbs_with_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE yaml_intent_patterns IS NOT NULL AND array_length(yaml_intent_patterns, 1) > 0) as verbs_with_yaml_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".dsl_verbs
+     WHERE intent_patterns IS NOT NULL AND array_length(intent_patterns, 1) > 0) as verbs_with_learned_patterns,
+    (SELECT COUNT(*) FROM "ob-poc".verb_pattern_embeddings WHERE embedding IS NOT NULL) as total_embeddings,
+    (SELECT COUNT(DISTINCT verb_name) FROM "ob-poc".verb_pattern_embeddings) as unique_verbs_embedded;
+
+
+--
+-- Name: VIEW v_verb_embedding_stats; Type: COMMENT; Schema: ob-poc; Owner: -
+--
+
+COMMENT ON VIEW "ob-poc".v_verb_embedding_stats IS 'Statistics for verb embedding coverage - split by YAML vs learned patterns';
+
+
 --
 -- Name: workflow_definitions; Type: TABLE; Schema: ob-poc; Owner: -
 --
@@ -21352,6 +21433,13 @@ CREATE INDEX idx_dsl_verbs_search ON "ob-poc".dsl_verbs USING gin (to_tsvector('
 CREATE INDEX idx_dsl_verbs_workflow ON "ob-poc".dsl_verbs USING gin (workflow_phases);
 
 
+--
+-- Name: idx_dsl_verbs_yaml_patterns; Type: INDEX; Schema: ob-poc; Owner: -
+--
+
+CREATE INDEX idx_dsl_verbs_yaml_patterns ON "ob-poc".dsl_verbs USING gin (yaml_intent_patterns) WHERE (yaml_intent_patterns IS NOT NULL);
+
+
 --
 -- Name: idx_dsl_versions_created_at; Type: INDEX; Schema: ob-poc; Owner: -
 --
@@ -27191,4 +27279,3 @@ ALTER TABLE ONLY teams.teams
 --
 
 \unrestrict UhevCCGW18lifr3G4hg8AXjj0hjxg6QrSVrFT4BMPDsJBWaTVdiJMbpLae7084Z
-
